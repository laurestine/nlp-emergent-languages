{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucAi-7qyjfIw"
      },
      "source": [
        "**Project description** :\n",
        "In the following notebook, we investigate to what extent languages induced by a two-player (sender to receiver) communication game share the linguistic properties of natural languages. More precisely, we study the role of the communication channel between the sender and the receiver.\n",
        "\n",
        "**Notebook permanent link** : \n",
        "If you wish to access this notebook in the future, please ue this link : https://colab.research.google.com/drive/1lNgQnARZxYwPOxq_3LvjDSsjro-y2MCR?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inRXqi3-qiVJ"
      },
      "source": [
        "## 🚨 Instructions 🚨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA0vg0oyqSva"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "In order to run this notebook properly on your Google Drive, please make sure to follow the following steps :\n",
        "    1. First, make sure that you have enabled access to a GPU hardware accelerator. In order to do so, go to : \n",
        "      'Runtime' > 'Change runtime type' > 'Hardware accelerator' -> 'GPU'\n",
        "    2. Then, before running \n",
        "\n",
        "```\n",
        "\n",
        "Please note that if you wish to directly see the results of the experiments implemented in the notebook below, please consult this project's [Weights & Biases dashboard](https://wandb.ai/volut3s/nlp-emergent-languages?workspace=user-volut3s). Feel free to consult our [Github repository](https://github.com/excitingtimes/encom) for a complete overview of the code of the experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQZEbkZlzids"
      },
      "source": [
        "*Note* : Run the following code in order to prevent you from being connected from Google Colab's VM :\n",
        "```\n",
        "function KeepClicking(){\n",
        "console.log(\"Clicking\");\n",
        "document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(KeepClicking,60000)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP7ZvN_e9GoV"
      },
      "source": [
        "\n",
        "### Main folders of the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AY-ZpBO9GYM"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = \"drive/My Drive/Projects/nlp_emergent_languages/\"\n",
        "CHECKPOINTS_DIR = PROJECT_DIR + 'checkpoints/'\n",
        "INTERACTIONS_DIR = PROJECT_DIR + 'interactions/' # Apparently, EGG does store interactions one level below the level provided \n",
        "DATASETS_DIR = PROJECT_DIR + 'datasets/'\n",
        "PRETRAINED_MODELS_DIR = '/content/' + PROJECT_DIR + 'pretrained_models/'\n",
        "FINETUNED_MODELS_DIR = '/content/' + PROJECT_DIR + 'finetuned_models/'\n",
        "\n",
        "DATASET_IMAGENET_DIR = 'imagenet/imagenet/'\n",
        "DATASET_TINY_IMAGENET_DIR = 'tiny-imagenet/tiny-imagenet-200/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE7vJS479G-C"
      },
      "source": [
        "### Dynamically define a checkpoint if you want to continue an experiment or evaluate a pretrained agents pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZCyygzd9GS-"
      },
      "outputs": [],
      "source": [
        "# CHECKPOINT_DIR = PROJECT_DIR + 'runs/'\n",
        "# CHECKPOINT_PATH = None # CHECKPOINT_DIR + 'your_checkpoint_folder_here/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2rnXIEE9HOF"
      },
      "source": [
        "### Wandb-related parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgouVFCpqQM8"
      },
      "outputs": [],
      "source": [
        "WANDB_API_KEY = \"your-own-api-key\"\n",
        "WANDB_PROJECT = \"nlp-emergent-languages\"\n",
        "WANDB_ENTITY = \"volut3s\"\n",
        "WANDB_NOTES = \"We assess the robustness and generalization / compositionality capabilities of emergent languages \\\n",
        "in a two-agent signaling game under channel noisyness constriants\"\n",
        "WANDB_EXPERIMENT_NAME=\"No channel constraints\"\n",
        "WANDB_EXPERIMENT_GROUP=\"vision-model-pretraining\"  # 'reconstruction-game', 'discrimination-game', 'vision-model-pretraining', 'ablation-study'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlPxrW_ymFjf"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y97NTBHpmBMW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS4rm7HLxmq0"
      },
      "source": [
        "#### Utility function for memory management :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVi7Mw73xm-o"
      },
      "outputs": [],
      "source": [
        "def free_memory(\n",
        "    model, \n",
        "    *args,\n",
        "):\n",
        "    # Now, we free the available memory in order to launch other training experiments.\n",
        "    print(\"Freeing memory ...\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    for x in args:\n",
        "        x = None\n",
        "        del x\n",
        "    print(\"Successfully freed some memory !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML9ju6MMzPZY"
      },
      "source": [
        "---\n",
        "# 0. 📚 Installing useful dependencies 📚\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHaUrFUHp0-K"
      },
      "outputs": [],
      "source": [
        "# EGG : Emergence of lanGuage in Games environment (see https://github.com/facebookresearch/EGG for more information)\n",
        "!pip install --quiet git+https://github.com/facebookresearch/EGG.git\n",
        "!pip install --quiet torchvision\n",
        "!pip install --quiet wandb\n",
        "!pip install --quiet pytorch_lightning\n",
        "!pip install --quiet h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owjOIEE9qEtY"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "import egg.core as core\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torchvision as tv\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "from PIL import ImageFilter\n",
        "from operator import itemgetter\n",
        "\n",
        "import copy\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "from pylab import rcParams\n",
        "from functools import partial\n",
        "from itertools import product\n",
        "from typing import Tuple, Optional, Union\n",
        "from collections import OrderedDict\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "c = copy.deepcopy # To copy neural modules without tying the weights (independent copies)\n",
        "\n",
        "def cycle(\n",
        "    loader,\n",
        "): # Iterates over a dataloader\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "rcParams['figure.figsize'] = 5, 10\n",
        "\n",
        "# For convenince and reproducibility, we set some EGG-level command line arguments here\n",
        "opts = core.init(params=['--random_seed=7',  # Will initialize numpy, torch, and python RNGs\n",
        "                         '--lr=1e-3',        # Sets the learning rate for the selected optimizer \n",
        "                         '--batch_size=32',\n",
        "                         '--optimizer=adam', # 'sgd', 'adagrad', 'adam'\n",
        "                         # '--fp16',\n",
        "                         '--update_freq=1',  # Updates learnable weights every x\n",
        "                         f'--checkpoint_dir=\"{PROJECT_DIR}\"',\n",
        "                         '--checkpoint_freq=10',\n",
        "                         '--validation_freq=5',\n",
        "                         # f'--load_from_checkpoint=\"{CHECKPOINT_PATH}\"',\n",
        "                         # '--tensorboard',\n",
        "                         ])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1YydYoNcMBY"
      },
      "source": [
        "#### Random **seed initialization** (for *reproducibility*) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5oYnG4DcMWs"
      },
      "outputs": [],
      "source": [
        "SET_RANDOM_SEED = False\n",
        "\n",
        "if SET_RANDOM_SEED:\n",
        "    hashed_sentence = 'emergent languages are very cool, yes indeed !'\n",
        "    get_seed = lambda s: hash(s) % (2**32 - 1)\n",
        "    SEED = get_seed(hashed_sentence)\n",
        "\n",
        "    # Setting the random seeds of Numpy, PyTorch and Random\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    def seed_worker(\n",
        "        worker_id,\n",
        "    ):\n",
        "        worker_seed = torch.initial_seed() % 2**32\n",
        "        np.random.seed(worker_seed)\n",
        "        random.seed(worker_seed)\n",
        "\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(0)\n",
        "\n",
        "    # Initialize the following parameters in the dataloader :\n",
        "    worker_init_fn = seed_worker\n",
        "    generator = g\n",
        "\n",
        "    # Avoid the following insofar as possible for efficiency purposes :\n",
        "    torch.use_deterministic_algorithms(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdx5hJdmBqWP"
      },
      "outputs": [],
      "source": [
        "def wandb_connect():\n",
        "    wandb_conx = wandb.login(key = WANDB_API_KEY)\n",
        "    print(f\"Connected to Wandb online interface : {wandb_conx}\")\n",
        "\n",
        "wandb_connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I1vwcGzqFTX"
      },
      "source": [
        "---\n",
        "#1. 👁 Vision feature extractor 👁\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5o3kOxKTVXP"
      },
      "source": [
        "## A. 🎦 Pretraining our own vision module (*proof of principle, do not use this technique further down*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ErMbAbrlbPn"
      },
      "source": [
        "### Defining the vision module architecture (custom example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5elCd1ipqTY1"
      },
      "outputs": [],
      "source": [
        "class Vision(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "    ):\n",
        "        super(Vision, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        x,\n",
        "    ):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "class PretrainNet(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        vision_module, \n",
        "        dim_vision_out=500,\n",
        "    ):\n",
        "        super(PretrainNet, self).__init__()\n",
        "        self.vision_module = vision_module\n",
        "        self.dim_vision_out = dim_vision_out\n",
        "        self.fc = nn.Linear(self.dim_vision_out, 10)\n",
        "        \n",
        "    def forward(\n",
        "        self, \n",
        "        x,\n",
        "    ):\n",
        "        x = self.vision_module(x)\n",
        "        x = self.fc(F.leaky_relu(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh3e3eY8OIUf"
      },
      "source": [
        "### Defining a data augmentation strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzIz1vg7YsSM"
      },
      "outputs": [],
      "source": [
        "# Defining forms of data augmentation in order to discourage overfitting of the induced language on the particular dataset\n",
        "transform_train = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor()])\n",
        "transform_val_test = T.ToTensor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3npZoQHlcZD"
      },
      "source": [
        "### Instantiating training and test dataloaders :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItwG5LLSqYtg"
      },
      "outputs": [],
      "source": [
        "def generate_dataloaders_from_remote(\n",
        "    dataset, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='mnist', \n",
        "    num_workers=1, \n",
        "    pin_memory=True, \n",
        "    val_test_ratio=(0.75, 0.25),\n",
        "):\n",
        "    kwargs = {'num_workers': num_workers, # In order to parallelize dataset loading : interesting :) \n",
        "            'pin_memory': pin_memory} if torch.cuda.is_available() else {}\n",
        "\n",
        "    batch_size = opts.batch_size\n",
        "\n",
        "    if name == 'places-365':\n",
        "        train_dataset = dataset(DATASETS_DIR + name\n",
        "                                + '/', split='train-standard', download=True, transform=transform_train)\n",
        "    elif name == 'svhn':\n",
        "        train_dataset = dataset(DATASETS_DIR + name + '/', split='train', download=True, transform=transform_train)\n",
        "    elif name == 'inaturalist':\n",
        "        train_dataset = dataset(DATASETS_DIR + name + '/', version='2021_train', download=True, transform=transform_train)\n",
        "    elif name == 'fake-data':\n",
        "        train_dataset = dataset(size=1_000, image_size=(3, 26, 26), num_classes=10, transform=transform_train)\n",
        "    elif name == 'caltech-101':\n",
        "        full_dataset = dataset(DATASETS_DIR + name + '/', target_type='category', download=True, transform=transform_train)\n",
        "    elif name == 'caltech-256':\n",
        "        full_dataset = dataset(DATASETS_DIR + name + '/', download=True, transform=transform_train)\n",
        "    else:\n",
        "        train_dataset = dataset(DATASETS_DIR + name + '/', train=True, download=True, transform=transform_train)\n",
        "\n",
        "    if name in ['caltech-101', 'caltech-256']:\n",
        "        len_train = int(0.85 * len(full_dataset))\n",
        "        len_val_test = len(full_dataset) - len_train\n",
        "        print(\"Caltech dataset : len_train={}, len_val_test={}\".format(len_train, len_val_test))\n",
        "        train_dataset, __test_dataset__ = torch.utils.data.random_split(full_dataset, lengths=[len_train, len_val_test])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                            batch_size=batch_size, \n",
        "                                            shuffle=True, \n",
        "                                            # worker_init_fn=worker_init_fn,\n",
        "                                            # generator=generator,\n",
        "                                            **kwargs)\n",
        "    \n",
        "    len_train = len(train_dataset)\n",
        "    print(\"Loading dataset : [{}]\".format(name))\n",
        "    print(\"\\nNumber of training samples : {}\".format(len_train))\n",
        "\n",
        "    if name =='places-365':\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', split='val', download=True, transform=transform_val_test)\n",
        "    elif name =='svhn':\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', split='test', download=True, transform=transform_val_test)\n",
        "    elif name == 'inaturalist':\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', version='2021_valid', download=True, transform=transform_val_test)\n",
        "    elif name == 'fake-data':\n",
        "        __test_dataset__ = dataset(size=100, image_size=(3, 26, 26), num_classes=10, transform=transform_val_test)\n",
        "    elif name in ['caltech-101', 'caltech-256']:\n",
        "        pass\n",
        "    else:\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', train=False, download=True, transform=transform_val_test)\n",
        "\n",
        "    len_val = int(val_test_ratio[0] * len(__test_dataset__))\n",
        "    len_test = len(__test_dataset__) - len_val\n",
        "    print(\"Number of validation samples : {}\".format(len_val))\n",
        "    print(\"Number of test samples : {}\".format(len_test))\n",
        "\n",
        "    val_dataset, test_dataset = torch.utils.data.random_split(__test_dataset__, [len_val, len_test])\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             batch_size=batch_size, \n",
        "                                             shuffle=True, \n",
        "                                             # worker_init_fn=worker_init_fn,\n",
        "                                             # generator=generator,\n",
        "                                             **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size, \n",
        "                                              shuffle=True, \n",
        "                                              # worker_init_fn=worker_init_fn,\n",
        "                                              # generator=generator,\n",
        "                                              **kwargs)\n",
        "\n",
        "    print(\"\\nBatch size : {}\".format(batch_size))\n",
        "    print(\"\\nLength of training dataloader (in batches) : {}\".format(len(train_loader)))\n",
        "    print(\"Length of validation dataloader (in batches) : {}\".format(len(val_loader)))\n",
        "    print(\"Length of test dataloader (in batches) : {}\".format(len(test_loader)))\n",
        "\n",
        "    split_dataloaders = {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader,\n",
        "        'test': test_loader,\n",
        "    }\n",
        "\n",
        "    return split_dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO2J2zfVljh5"
      },
      "source": [
        "### Training our custom vision model :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhFZw0icqanF"
      },
      "outputs": [],
      "source": [
        "# Defining the optimization routine of the model\n",
        "vision = Vision()\n",
        "class_prediction = PretrainNet(vision) #  note that we pass vision - which we want to pretrain\n",
        "optimizer = core.build_optimizer(class_prediction.parameters()) #  uses command-line parameters we passed to core.init\n",
        "class_prediction = class_prediction.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1oRZQzQmH0k"
      },
      "outputs": [],
      "source": [
        "transform = T.ToTensor()\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "transform_train = T.ToTensor()\n",
        "\n",
        "batch_size = opts.batch_size # set via the CL arguments above\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.KMNIST('./data', train=True, download=True,\n",
        "           transform=transform),\n",
        "           batch_size=batch_size, shuffle=True, **kwargs)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.KMNIST('./data', train=False, transform=transform),\n",
        "           batch_size=batch_size, shuffle=False, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGhQjTVmqoem"
      },
      "outputs": [],
      "source": [
        "for epoch in range(10):\n",
        "    mean_loss, n_batches = 0, 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # print(data.shape, target.shape)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = class_prediction(data)\n",
        "        # print(output.shape)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        mean_loss += loss.mean().item()\n",
        "        n_batches += 1\n",
        "        \n",
        "    print(f'Train Epoch: {epoch}, mean loss: {mean_loss / n_batches}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBvllxE2Te8K"
      },
      "source": [
        "## B. 🌏 Import a SOTA pretrained model (*preferred technique*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz5ZqQAJk9sz"
      },
      "source": [
        "### [*Optional, only run once*] --- Run the code below in order to expand *tiny-imagenet.zip* ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSdiEZ3CX8Rw"
      },
      "outputs": [],
      "source": [
        "# !pwd\n",
        "# !ls drive/My\\ Drive/Projects/nlp_emergent_languages/datasets/\n",
        "# !unzip drive/My\\ Drive/Projects/nlp_emergent_languages/datasets/tiny-imagenet -d drive/My\\ Drive/Projects/nlp_emergent_languages/datasets/tiny-imagenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z17epV1XlHiw"
      },
      "source": [
        "### Data augmentation for the visual domain :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVHCt5wpieYh"
      },
      "outputs": [],
      "source": [
        "class GaussianBlur():\n",
        "    def __init__(\n",
        "        self, \n",
        "        sigma=[0.1, 2.0],\n",
        "    ):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x\n",
        "\n",
        "class TransformsAugment():\n",
        "    def __init__(\n",
        "        self, \n",
        "        size, \n",
        "        multi_channel=True,\n",
        "    ):\n",
        "        print(\"Transforms Augment\")\n",
        "        s = 1\n",
        "        color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "        transformations = [\n",
        "            T.RandomResizedCrop(size=size),\n",
        "            T.RandomApply([color_jitter], p=0.8),\n",
        "            T.RandomGrayscale(p=0.2),\n",
        "            T.RandomApply([GaussianBlur([0.1, 2.0])], p=0.5),\n",
        "            T.RandomHorizontalFlip(),  # with 0.5 probability\n",
        "            T.ToTensor(),\n",
        "        ]\n",
        "        # We \"pseudo-colorize\" the image by broadcasting to the three dimensions\n",
        "        if not multi_channel:\n",
        "            # Solution : number 1 : we simply broadcast the pixel information over all three channels,\n",
        "            # but the main problem is that this is suboptimal\n",
        "            # transformations.append(T.Lambda(lambda x: x[0:1, :, :]))\n",
        "            transformations.append(T.Lambda(lambda x: x.repeat(3,1,1)))\n",
        "\n",
        "            print(\"Not multi-channel\")\n",
        "\n",
        "        \"\"\"\n",
        "        transformations.append(\n",
        "            T.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        )\n",
        "        \"\"\"\n",
        "        self.transform = T.Compose(transformations)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x_trans = self.transform(x)\n",
        "        return x_trans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt14axsCOPAG"
      },
      "source": [
        "### Defining a data augmentation strategy :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z56CftZIORfu"
      },
      "outputs": [],
      "source": [
        "# transform_train = TransformsAugment(size=256, imagenet=True)\n",
        "# transform_val_test = T.ToTensor()\n",
        "# transform_train = T.ToTensor()\n",
        "# transform_val_test = T.ToTensor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFkiquZ-lObR"
      },
      "source": [
        "### Instantiating training and test dataloaders :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwj7oeAiSsre"
      },
      "outputs": [],
      "source": [
        "def generate_dataloaders_from_local(\n",
        "    path, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    num_workers=2, \n",
        "    pin_memory=True, \n",
        "    val_test_ratio=(0.75, 0.25),\n",
        "):\n",
        "    kwargs = {'num_workers': num_workers, # In order to parallelize dataset loading : interesting :) \n",
        "            'pin_memory': pin_memory} if torch.cuda.is_available() else {}\n",
        "\n",
        "    batch_size = opts.batch_size\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(root=path + 'train/', transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                            batch_size=batch_size, \n",
        "                                            shuffle=True, \n",
        "                                            # worker_init_fn=worker_init_fn,\n",
        "                                            # generator=generator,\n",
        "                                            **kwargs)\n",
        "\n",
        "    __test_dataset__ = datasets.ImageFolder(path + 'val/', transform=transform_val_test)\n",
        "\n",
        "    len_val = int(val_test_ratio[0] * len(__test_dataset__))\n",
        "    len_test = len(__test_dataset__) - len_val\n",
        "    print(\"Number of validation samples : {}\".format(len_val))\n",
        "    print(\"Number of test samples : {}\".format(len_test))\n",
        "\n",
        "    val_dataset, test_dataset = torch.utils.data.random_split(__test_dataset__, [len_val, len_test])\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             batch_size=batch_size, \n",
        "                                             shuffle=True, \n",
        "                                             # worker_init_fn=worker_init_fn,\n",
        "                                             # generator=generator,\n",
        "                                             **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size, \n",
        "                                              shuffle=True, \n",
        "                                              # worker_init_fn=worker_init_fn,\n",
        "                                              # generator=generator,\n",
        "                                              **kwargs)\n",
        "\n",
        "    print(\"\\nLength of training dataloader : {}\".format(len(train_loader)))\n",
        "    print(\"Length of validation dataloader : {}\".format(len(val_loader)))\n",
        "    print(\"Length of test dataloader : {}\".format(len(test_loader)))\n",
        "\n",
        "    split_dataloaders = {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader,\n",
        "        'test': test_loader,\n",
        "    }\n",
        "\n",
        "    return split_dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwBi9333PdLU"
      },
      "source": [
        "### Downloading a few natural images datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6dX5O8coPNU"
      },
      "outputs": [],
      "source": [
        "split_dataloaders = {\n",
        "    'train': None,\n",
        "    'val': None,\n",
        "    'test': None,\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'cifar-10': split_dataloaders,\n",
        "    'cifar-100': split_dataloaders,\n",
        "    'mnist': split_dataloaders,\n",
        "    'tiny-imagenet': split_dataloaders,\n",
        "    'fashion-mnist': split_dataloaders,\n",
        "    'q-mnist': split_dataloaders,\n",
        "    'k-mnist': split_dataloaders,\n",
        "    'svhn': split_dataloaders,\n",
        "    'caltech-101': split_dataloaders,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZEEhV2GxtXe"
      },
      "outputs": [],
      "source": [
        "image_datasets.update({\n",
        "    'imagenet': split_dataloaders,\n",
        "    'places-365': split_dataloaders,\n",
        "    'inaturalist': split_dataloaders,\n",
        "    'fake-data': split_dataloaders,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiHS__mVPgEO"
      },
      "source": [
        "#### 🏞 CIFAR-10 & CIFAR-100 🏞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St37lOYcPe71"
      },
      "outputs": [],
      "source": [
        "image_datasets['cifar-10'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.CIFAR10, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='cifar-10',\n",
        ")\n",
        "image_datasets['cifar-100'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.CIFAR100, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='cifar-100',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4IQ6-CSPpSE"
      },
      "source": [
        "#### 🔢 MNIST 🔢"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtS8uAB_Ppjz"
      },
      "outputs": [],
      "source": [
        "image_datasets['mnist'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.MNIST,\n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='mnist',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aba9WFWLPp9j"
      },
      "source": [
        "#### 🪐 ImageNet & TinyImageNet 🪐 *(we retrieve both of them from a local repository)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNU3bFnKPqMq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "image_datasets['imagenet'] = lambda transform_train, transform_val_test: generate_dataloaders_from_local(\n",
        "    DATASETS_DIR + DATASET_IMAGENET_DIR,\n",
        "    transform_train, \n",
        "    transform_val_test,\n",
        ")\n",
        "image_datasets['tiny-imagenet'] = lambda transform_train, transform_val_test: generate_dataloaders_from_local(\n",
        "    DATASETS_DIR + DATASET_TINY_IMAGENET_DIR,\n",
        "    transform_train, \n",
        "    transform_val_test,\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4k30wW_PsKu"
      },
      "source": [
        "#### 🥋 FashionMNIST 🥋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f6FNqTQPsZT"
      },
      "outputs": [],
      "source": [
        "image_datasets['fashion-mnist'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.FashionMNIST,\n",
        "    transform_train, \n",
        "    transform_val_test,\n",
        "    name='fashion-mnist',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg9wFXusPsm1"
      },
      "source": [
        "#### 🌉 Places365 🌉 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt1AqAZhPs51"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "image_datasets['places-365'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.Places365, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='places-365',\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWL0vnpIPtKT"
      },
      "source": [
        "#### 🌿 iNaturalist 🌿"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-YODW6GPttJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "image_datasets['inaturalist'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.INaturalist, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='inaturalist',\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RFZNp85kBSl"
      },
      "source": [
        "#### 🤡 FakeData 🤡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVLk3lYnkBlj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "image_datasets['fake-data'] = lambda: generate_dataloaders_from_remote(\n",
        "    datasets.FakeData, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='fake-data',\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcjlYrnCkB3o"
      },
      "source": [
        "#### 🧾 QMNIST 🧾"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv6WuTYgkCSG"
      },
      "outputs": [],
      "source": [
        "image_datasets['q-mnist'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.QMNIST, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='q-mnist',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnHcjwsXkCsq"
      },
      "source": [
        "#### 🔖 KMNIST 🔖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc_q6tUpkC7g"
      },
      "outputs": [],
      "source": [
        "image_datasets['k-mnist'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.KMNIST, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='k-mnist',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4J5BsVzkDHf"
      },
      "source": [
        "#### 🗻 SVHN 🗻"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Atm3a5jtkDYr"
      },
      "outputs": [],
      "source": [
        "image_datasets['svhn'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.SVHN,\n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='svhn',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4STca6BkDoU"
      },
      "source": [
        "#### 🪑 Caltech-101 🪑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esr5kBamkD-c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "image_datasets['caltech-101'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.Caltech101, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='caltech-101',\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrIEcQJapclN"
      },
      "source": [
        "#### 💺 Caltech-256 💺"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu25Tes8pc5z"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "image_datasets['caltech-256'] = lambda transform_train, transform_val_test: generate_dataloaders_from_remote(\n",
        "    datasets.Caltech101, \n",
        "    transform_train, \n",
        "    transform_val_test, \n",
        "    name='caltech-256',\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRiSrc9aCnzQ"
      },
      "source": [
        "#### Standard image sizes for all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVTFW7AMCqHJ"
      },
      "outputs": [],
      "source": [
        "sizes = {\n",
        "    'cifar-10': 32,\n",
        "    'cifar-100': 32,\n",
        "    'mnist': 28,\n",
        "    'imagenet': 256,\n",
        "    'tiny-imagenet': 64,\n",
        "    'fashion-mnist': 28,\n",
        "    'places-365': 256,\n",
        "    'inaturalist': 256, # the dimension to resize the images to, but they may be actually higher-def (up to 2,048 px)\n",
        "    'fake-data': 224,\n",
        "    'q-mnist': 28,\n",
        "    'k-mnist': 28,\n",
        "    'svhn': 32,\n",
        "    'caltech-101': 64, # there are actually sizes for each image - therefore we round up to the average value\n",
        "    'caltech-256': 64, # same\n",
        "}\n",
        "n_channels = {\n",
        "    'cifar-10': 3,\n",
        "    'cifar-100': 3,\n",
        "    'mnist': 1,\n",
        "    'imagenet': 3,\n",
        "    'tiny-imagenet': 3,\n",
        "    'fashion-mnist': 1,\n",
        "    'places-365': 3,\n",
        "    'inaturalist': 3,\n",
        "    'fake-data': 3,\n",
        "    'q-mnist': 1,\n",
        "    'k-mnist': 1,\n",
        "    'svhn': 1,\n",
        "    'caltech-101': 3,\n",
        "    'caltech-256': 3,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtDjTIrTlWLH"
      },
      "source": [
        "### Downloading a few pretrained vision models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRNcblrvYp3L"
      },
      "outputs": [],
      "source": [
        "resnets = {\n",
        "        \"resnet-18\": (lambda: tv.models.resnet18(pretrained=True, progress=True)),\n",
        "        \"resnet-34\": (lambda: tv.models.resnet34(pretrained=True, progress=True)),\n",
        "        \"resnet-50\": (lambda: tv.models.resnet50(pretrained=True, progress=True)),\n",
        "        \"resnet-101\": (lambda: tv.models.resnet101(pretrained=True, progress=True)),\n",
        "        \"resnet-152\": (lambda: tv.models.resnet152(pretrained=True, progress=True)),\n",
        "    }\n",
        "\n",
        "efficientnets = {\n",
        "    \"efficientnet-b0\": (lambda: tv.models.efficientnet_b0(pretrained=True, progress=True)),\n",
        "    \"efficientnet-b1\": (lambda: tv.models.efficientnet_b1(pretrained=True, progress=True)),\n",
        "    \"efficientnet-b2\": (lambda: tv.models.efficientnet_b2(pretrained=True, progress=True)),\n",
        "    \"efficientnet-b3\": (lambda: tv.models.efficientnet_b3(pretrained=True, progress=True)),\n",
        "    \"efficientnet-b4\": (lambda: tv.models.efficientnet_b4(pretrained=True, progress=True)),\n",
        "    \"efficientnet-b5\": (lambda: tv.models.efficientnet_b5(pretrained=True, progress=True)),\n",
        "    \"efficientnet-b6\": (lambda: tv.models.efficientnet_b6(pretrained=True, progress=True)),\n",
        "    \"efficientnet-b7\": (lambda: tv.models.efficientnet_b7(pretrained=True, progress=True)),\n",
        "}\n",
        "\n",
        "def get_vision_module(version: str):\n",
        "    \"\"\"\n",
        "    Loads ResNet & EfficientNet encoders from torchvision along with the final features number\n",
        "    \"\"\"\n",
        "\n",
        "    os.environ['TORCH_HOME'] = PRETRAINED_MODELS_DIR # Used in order to specify where to save the pretrained models, so as not to load them again in the future\n",
        "\n",
        "    if (version not in resnets) and (version not in efficientnets):\n",
        "        raise KeyError(f\"{version} is not a valid ResNet / EfficientNet version\")\n",
        "\n",
        "    models_library = {**resnets, **efficientnets}\n",
        "\n",
        "    model = models_library[version]()\n",
        "    \n",
        "    features_dim = model.fc.out_features\n",
        "\n",
        "    return model, features_dim\n",
        "\n",
        "try:\n",
        "    get_vision_module('downloading')\n",
        "except:\n",
        "    print(\"Pretrained vision models successfully downloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7rEXbrmlpjv"
      },
      "source": [
        "### Instantiating our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiew0aBnlntR"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "model_name = \"resnet-18\"\n",
        "\n",
        "# vision, dim_vision_out = get_vision_module(model_name)\n",
        "dim_vision_out = 500\n",
        "class_prediction = PretrainNet(vision, dim_vision_out=dim_vision_out)\n",
        "optimizer = core.build_optimizer(class_prediction.parameters()) #  uses command-line parameters we passed to core.init\n",
        "class_prediction = class_prediction.to(device)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTtFl9bTvHmB"
      },
      "source": [
        "## C. 🖌 Finetuning our vision models on the specified dataset\n",
        "\n",
        "Please refer to this specific notebook for further details : https://colab.research.google.com/drive/12m-SOfFKWQzys5h-z6p8caJ8-6Esgu1e?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyCt1nkOqFaQ"
      },
      "source": [
        "---\n",
        "# 2. 🗺 Defining the **agents**' internal models\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53_GBnN6rp-T"
      },
      "source": [
        "## A. 🗣 **Sender** agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD7tqnCJgNT6"
      },
      "source": [
        "#### Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz_g2v-fgMZl"
      },
      "outputs": [],
      "source": [
        "intertwine = lambda a, b: [x for pair in zip(a, b) for x in pair]\n",
        "print(intertwine([1, 3, 5], [2, 4]))\n",
        "\n",
        "def get_mlp(\n",
        "    input_size=400, \n",
        "    output_size=400, \n",
        "    hidden_sizes=[],\n",
        "):\n",
        "    n_h = len(hidden_sizes)\n",
        "\n",
        "    linears = [nn.Linear(input_size, hidden_sizes[0])]\n",
        "    for i in range(n_h):\n",
        "        if i == n_h - 1:\n",
        "            linears.append(nn.Linear(hidden_sizes[i], output_size))\n",
        "        else:\n",
        "            linears.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
        "    activations = [nn.ReLU() for _ in range(n_h)]\n",
        "\n",
        "    mix = intertwine(linears, activations) + [linears[-1]]\n",
        "    keys = [f\"linear_{i//2}\" if (i%2 == 0) else f\"relu_{i//2}\" for i in range(len(mix))]\n",
        "\n",
        "    mlp = nn.Sequential(OrderedDict(zip(keys, mix)))\n",
        "\n",
        "    return mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnKN0QuPrD_A"
      },
      "outputs": [],
      "source": [
        "class Sender(nn.Module):\n",
        "    def __init__(self, vision, input_size=400, output_size=400, hidden_sizes=[]):\n",
        "        super(Sender, self).__init__()\n",
        "\n",
        "        n_h = len(hidden_sizes)\n",
        "        if n_h >= 1:\n",
        "            self.fc = get_mlp(input_size, output_size, hidden_sizes)\n",
        "        else:\n",
        "            self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "        self.vision = vision\n",
        "        \n",
        "    def forward(self, x, aux_input=None):\n",
        "        with torch.no_grad():\n",
        "            x = self.vision(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "__sender__ = Sender(vision, input_size=400, output_size=400)\n",
        "__sender__ = Sender(vision, input_size=400, output_size=400, hidden_sizes=[600, 800, 600])\n",
        "del __sender__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlnytA2Qrrzc"
      },
      "source": [
        "## B. 👂 **Receiver** agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t9sCghWrPE2"
      },
      "outputs": [],
      "source": [
        "class Receiver(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        input_size=400, \n",
        "        output_size=784, \n",
        "        hidden_sizes=[],\n",
        "    ):\n",
        "        super(Receiver, self).__init__()\n",
        "\n",
        "        n_h = len(hidden_sizes)\n",
        "        if n_h >= 1:\n",
        "            self.fc = get_mlp(input_size, output_size, hidden_sizes)\n",
        "        else:\n",
        "            self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        channel_input, \n",
        "        receiver_input=None, \n",
        "        aux_input=None,\n",
        "    ):\n",
        "        x = self.fc(channel_input)\n",
        "\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "__receiver__ = Receiver(input_size=400, output_size=784)\n",
        "__receiver__ = Receiver(input_size=400, output_size=784, hidden_sizes=[600, 800, 600])\n",
        "del __receiver__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xk8TIyKqFf4"
      },
      "source": [
        "---\n",
        "# 3. 🗺 Defining the game **mechanics** and the **environment** 🗺\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFJRzGuypIFn"
      },
      "source": [
        "## A. 🎮 Game wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM8n08thZhg3"
      },
      "source": [
        "#### Accuracy loss  (*non-differentiable*) : **Discrimination Game**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rStF3owcrEdM"
      },
      "outputs": [],
      "source": [
        "def loss_accuracy_discrimination(\n",
        "    _sender_input, \n",
        "    _message, \n",
        "    _receiver_input, \n",
        "    receiver_output, \n",
        "    labels, \n",
        "    _aux_input,\n",
        "):\n",
        "    \"\"\"\n",
        "    Accuracy loss - non-differetiable hence cannot be used with GS\n",
        "    \"\"\"\n",
        "    acc = (labels == receiver_output).float()\n",
        "    return -acc, {\"acc\": acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ3LPPuqZkHy"
      },
      "source": [
        "#### Negative log-likelihood loss (*differentiable*) : **Discrimination Game**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU9igjF7Zked"
      },
      "outputs": [],
      "source": [
        "def loss_nll_discrimination(\n",
        "    _sender_input, \n",
        "    _message, \n",
        "    _receiver_input, \n",
        "    receiver_output, \n",
        "    labels, \n",
        "    _aux_input,\n",
        "):\n",
        "    \"\"\"\n",
        "    NLL loss - differentiable and can be used with both GS and Reinforce\n",
        "    \"\"\"\n",
        "    nll = F.nll_loss(receiver_output, labels, reduction=\"none\")\n",
        "    acc = (labels == receiver_output.argmax(dim=1)).float().mean()\n",
        "    return nll, {\"acc\": acc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lakxHnZWYL5L"
      },
      "source": [
        "#### BCE loss (*differentiable*) : **Reconstruction Game**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COPsh0GzYLrp"
      },
      "outputs": [],
      "source": [
        "def loss_bce_reconstruction(\n",
        "    sender_input, \n",
        "    _message, \n",
        "    _receiver_input, \n",
        "    receiver_output, \n",
        "    _labels, \n",
        "    _aux_input=None,\n",
        "):\n",
        "    global NUM_CHANNELS\n",
        "\n",
        "    # reconstruction_dim = 784\n",
        "\n",
        "    if True:\n",
        "        if NUM_CHANNELS == 1:\n",
        "            reconstruction_dim = int(sender_input.shape[2] ** 2)\n",
        "            loss = F.binary_cross_entropy(receiver_output, sender_input[:, 0:1, :, :].view(-1, reconstruction_dim), reduction='none').mean(dim=1)\n",
        "        else:\n",
        "            reconstruction_dim = int(NUM_CHANNELS * (sender_input.shape[2] ** 2))\n",
        "            loss = F.binary_cross_entropy(receiver_output, sender_input.view(-1, reconstruction_dim), reduction='none').mean(dim=1)\n",
        "\n",
        "    # loss = F.binary_cross_entropy(receiver_output, sender_input.view(-1, reconstruction_dim), reduction='none').mean(dim=1)\n",
        "    \n",
        "    return loss, {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5txjsoYpLYO"
      },
      "source": [
        "## B. 🏅 Communication **channel** and **reward** function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foNbdYmybjY9"
      },
      "source": [
        "We propose to model realistic communication between two agents over a channel in two ways. First, we propose to model the **confusion between similar phonemes** (*embedded* perspective on language production) through various cost functions, more or less faithful to linguistic models and which we compare through our experiments :\n",
        "\n",
        "\n",
        "1.   **Uniform** : \n",
        "2.   **1-dimensional similarity** : \n",
        "3.   **Chromatic similarity** : \n",
        "4.   **2-dimensional similarity** : \n",
        "5.   **Phoneme-accurate similarity** : \n",
        "6.   **Keyboard-accurate similarity** : \n",
        "7.   **Tree-hierarchical similarity** : \n",
        "\n",
        "\n",
        "\n",
        "Second, we propose to model the stochasticity of the communication channel through random corruption operators transforming the message sent by the **sender** agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0fM3k3QqSRm"
      },
      "source": [
        "#### *Sender* & *Receiver*'s **vocabulary** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCNyeC6Xv1eY"
      },
      "outputs": [],
      "source": [
        "law_exp = lambda mu, x: (1.0 / mu) * np.exp(-mu / x)\n",
        "\n",
        "class Vocabulary():\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_model='uniform',\n",
        "        vocab_size=26,\n",
        "        vocab_loss_c=1.0,\n",
        "        vocab_loss_mute=10.0,\n",
        "        vocab_mu_dist=1.0,\n",
        "        vocab_temperature=0.5,\n",
        "    ):\n",
        "        self.model = vocab_model\n",
        "        self.temperature = vocab_temperature\n",
        "        self.size = vocab_size\n",
        "        # Note : the first symbol of index 0 is used to denote the EOS token. It is not taken into account\n",
        "        # when computing the cost function across the communication channel\n",
        "\n",
        "        self.loss_c = vocab_loss_c\n",
        "        self.loss_mute = vocab_loss_mute\n",
        "        self.mu_dist = vocab_mu_dist\n",
        "        \n",
        "    def __compute_distance__(\n",
        "        self,\n",
        "        x_in: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        # x_in  : bs x max_len\n",
        "        # x_out : bs x (max_len - 1) --> x_out[i, j] corresponds to distance between x_in[i, j] and x_in[i, j + 1]\n",
        "\n",
        "        x_dist = torch.zeros_like(x_in)\n",
        "        if (self.model == 'uniform'):\n",
        "            x_dist = torch.ones_like(x_in)\n",
        "        elif (self.model == '1d'):\n",
        "            for i in range(x_in.shape[0]):\n",
        "                if x_in[i, 0] == 0:\n",
        "                    x_dist[i, 0] = self.loss_mute\n",
        "                for j in range(x_in.shape[1] - 1):\n",
        "                    if x_in[i, j + 1] == 0:\n",
        "                        break\n",
        "                    d = np.abs(x_in[i, j] - x_in[i, j + 1])\n",
        "                    x_dist[i, j] = law_exp(self.mu_dist, d)\n",
        "                    \n",
        "        elif (self.model == 'chromatic'):\n",
        "            pass\n",
        "\n",
        "        elif (self.model == '2d'):\n",
        "            size_x = int(np.sqrt(self.size))\n",
        "            size_y = self.size // size_x\n",
        "            for i in range(x_in.shape[0]):\n",
        "                if x_in[i, 0] == 0:\n",
        "                    x_dist[i, 0] = self.loss_mute\n",
        "                for j in range(x_in.shape[1] - 1):\n",
        "                    if x_in[i, j + 1] == 0:\n",
        "                        break\n",
        "                    coor_x = (x_in[i, j] % size_x, x_in[i, j + 1] % size_x)\n",
        "                    coor_y = (x_in[i, j] // size_x, x_in[i, j + 1] // size_y)\n",
        "\n",
        "                    d_x_2 = (coor_x[0] - coor_x[1])**2\n",
        "                    d_y_2 = (coor_y[0] - coor_y[1])**2\n",
        "\n",
        "                    d = np.sqrt(d_x_2 + d_y_2)\n",
        "\n",
        "                    x_dist[i, j] = law_exp(self.mu_dist, d)\n",
        "\n",
        "        elif (self.model == 'phoneme_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.model == 'keyboard_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.model == 'tree_hierarchical'):\n",
        "            pass\n",
        "\n",
        "        return x_dist\n",
        "        \n",
        "    def compute_cost(\n",
        "        self,\n",
        "        x_in: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        # x_dist : bs x max_len\n",
        "        # loss   : bs\n",
        "\n",
        "        x_dist = self.__compute_distance__(x_in)\n",
        "\n",
        "        # We sum-reduce along the batch dimension\n",
        "        sender_loss = torch.einsum('ij->i', x_dist)\n",
        "        return sender_loss, x_dist\n",
        "\n",
        "vocabulary = Vocabulary(vocab_model='uniform', vocab_size=10)\n",
        "__x_in__ = torch.randint(0, 25, (4, 10,))\n",
        "__loss__, _ = vocabulary.compute_cost(__x_in__)\n",
        "# print(__loss__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otFMaiFAqZTF"
      },
      "source": [
        "#### Helper function to visualize the induced language in a more readable format, across an entire batch along with labels :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPRY72EiaOxm"
      },
      "outputs": [],
      "source": [
        "def make_readable_communication(\n",
        "        x, \n",
        "        string,\n",
        "        bs,\n",
        "        max_len,\n",
        "        lower=True,\n",
        "    ):\n",
        "        shift_voc = 97 if lower else 65\n",
        "        \n",
        "        for i in range(bs):\n",
        "            string.append('')\n",
        "            for j in range(max_len):\n",
        "                if x[i, j] == 0:\n",
        "                    string[i] += '.'\n",
        "                    break\n",
        "                else:\n",
        "                    string[i] += chr(x[i, j] + shift_voc - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5He-YdHvqhGo"
      },
      "outputs": [],
      "source": [
        "def visualize_batch_communication(\n",
        "    x_in, \n",
        "    x_out=None, \n",
        "    label_in=None, \n",
        "    label_out=None, \n",
        "    lower=True,\n",
        "):\n",
        "    bs, max_len_in = x_in.shape\n",
        "    string_in, string_out = [], []\n",
        "    \n",
        "    make_readable_communication(x_in, string_in, bs, max_len_in, lower)\n",
        "    if (x_out is not None):\n",
        "        max_len_out = x_out.shape[1]\n",
        "        make_readable_communication(x_out, string_out, bs, max_len_out, lower)\n",
        "\n",
        "    for i in range(bs):\n",
        "        if (label_in is not None) and (label_out is not None):  \n",
        "            ground_truth_comparison = f'[I = {label_in[i]} / O = {label_out[i]}]'\n",
        "        else:\n",
        "            ground_truth_comparison = ''\n",
        "        if (x_out is not None):\n",
        "            received_message = '      -> ‖CHANNEL‖ ->      ⟥' + string_out[i].ljust(max_len_out) + '⟤      -> R      '\n",
        "        else:\n",
        "            received_message = ''\n",
        "        print(f'[{i+1}/{bs}]'.ljust(10) + 'S ->      ' + \n",
        "                '⟥' + string_in[i].ljust(max_len_in) + '⟤' + \n",
        "                received_message + \n",
        "                ground_truth_comparison)\n",
        "\n",
        "visualize_batch_communication(__x_in__, __x_in__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oaM8t6oqUWK"
      },
      "source": [
        "#### **Noisy** communication **channel** and **cost function** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTi6aBhhpLr0"
      },
      "outputs": [],
      "source": [
        "class Channel():\n",
        "    def __init__(\n",
        "        self,\n",
        "        max_len=3,\n",
        "        channel_top_k=10,\n",
        "        channel_temperature=0.8,\n",
        "        vocabulary=Vocabulary(),\n",
        "        p_random_insertion=0.05,\n",
        "        p_random_deletion=0.05,\n",
        "        p_random_permutation=0.05,\n",
        "        p_random_corruption=0.05,\n",
        "        corruption_function=['insertion', 'deletion', 'permutatio', 'corruption'],\n",
        "    ):\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Corruption sampling parameters\n",
        "        self.top_k = channel_top_k\n",
        "        self.temperature = channel_temperature\n",
        "        self.vocabulary = vocabulary\n",
        "\n",
        "        self.p_random_insertion = p_random_insertion\n",
        "        self.p_random_deletion = p_random_deletion\n",
        "        self.p_random_permutation = p_random_permutation\n",
        "        self.p_random_corruption = p_random_corruption\n",
        "\n",
        "        self.corruption_function = corruption_function\n",
        "\n",
        "    def __random_insert__(\n",
        "        self,\n",
        "        x_in: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        # Randomly inserts tokens in the input sentence\n",
        "        # x_in : bs x max_len\n",
        "\n",
        "        if self.p_random_insertion == 0.:\n",
        "            return x_in\n",
        "\n",
        "        if (self.vocabulary.model == 'uniform'):\n",
        "            x_out = torch.zeros_like(x_in, device=x_in.device)\n",
        "\n",
        "            x_0 = torch.zeros((x_in.shape[0], 1)).to(x_in.device)\n",
        "            \n",
        "            for b in range(x_in.shape[0]):\n",
        "                i, j = 0, 0\n",
        "                while (j < x_in.shape[1]) and (i < x_in.shape[1]):\n",
        "                    if random.uniform(0, 1) < self.p_random_insertion:\n",
        "                        total_supplement = x_out.shape[1] - x_in.shape[1]\n",
        "                        current_supplement = j - i\n",
        "                        if (current_supplement == total_supplement) or (i + 1 == x_out.shape[1]):\n",
        "                            x_out = torch.cat((x_out, x_0,), dim=1)\n",
        "                        x_out[b, i] = random.randint(1, self.vocabulary.size)\n",
        "                        i += 1\n",
        "                    else:\n",
        "                        x_out[b, i] = x_in[b, j]\n",
        "                        i += 1\n",
        "                        j += 1\n",
        "\n",
        "            \n",
        "\n",
        "        elif (self.vocabulary.model == '1d'):\n",
        "            pass\n",
        "        \n",
        "        elif (self.vocabulary.model == 'chromatic'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == '2d'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'phoneme_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'keyboard_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'tree_hierarchical'):\n",
        "            pass\n",
        "\n",
        "        return x_out\n",
        "\n",
        "    def __random_delete__(\n",
        "        self,\n",
        "        x_in: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        # Randomly deletes tokens in the input sentence\n",
        "        # x_in : bs x max_len\n",
        "\n",
        "        if self.p_random_deletion == 0.:\n",
        "            return x_in\n",
        "\n",
        "        if (self.vocabulary.model == 'uniform'):\n",
        "            x_out = torch.zeros_like(x_in, device=x_in.device)\n",
        "            \n",
        "            for b in range(x_in.shape[0]):\n",
        "                i, j = 0, 0\n",
        "                while j < x_in.shape[1]:\n",
        "                    if x_in[b, i] == 0:\n",
        "                        break\n",
        "                    if random.uniform(0, 1) < self.p_random_deletion:\n",
        "                        j += 1\n",
        "                    if j < x_in.shape[1] - 1:\n",
        "                        x_out[b, i] = x_in[b, j]\n",
        "                    i += 1\n",
        "                    j += 1\n",
        "\n",
        "        elif (self.vocabulary.model == '1d'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'chromatic'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == '2d'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'phoneme_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'keyboard_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'tree_hierarchical'):\n",
        "            pass\n",
        "\n",
        "        return x_out\n",
        "\n",
        "    def __random_permute__(\n",
        "        self,\n",
        "        x_in: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        # Randomly permutes arbitrary pairs of tokens in the input sentence, according to the vocabulary distance function defined\n",
        "        # in the Vocabulary class instance\n",
        "        # x_in : bs x max_len\n",
        "\n",
        "        if self.p_random_permutation == 0.:\n",
        "            return x_in\n",
        "\n",
        "        if (self.vocabulary.model == 'uniform'):\n",
        "            x_out = copy.deepcopy(x_in).to(x_in.device)\n",
        "            \n",
        "            for b in range(x_out.shape[0]):\n",
        "                for i in range(x_out.shape[1]):\n",
        "                    try:\n",
        "                        index_eos = (-x_out[b, :]).argmax(1)\n",
        "                    except:\n",
        "                        index_eos = x_out.shape[1]\n",
        "\n",
        "                    if random.uniform(0, 1) < self.p_random_permutation:\n",
        "                        # SHOULD IT BE -1 or not -1 ????? CHECK THAT !\n",
        "                        swap_index = random.randint(0, index_eos - 1)\n",
        "                        # print(x_out[b, i], x_out[b, swap_index])\n",
        "                        x_out[b, i], x_out[b, swap_index] = x_out[b, swap_index].item(), x_out[b, i].item()\n",
        "                        # print(x_out[b, i], x_out[b, swap_index])\n",
        "\n",
        "        elif (self.vocabulary.model == '1d'):\n",
        "            pass\n",
        "        \n",
        "        elif (self.vocabulary.model == 'chromatic'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == '2d'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'phoneme_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'keyboard_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'tree_hierarchical'):\n",
        "            pass\n",
        "\n",
        "        return x_out\n",
        "\n",
        "    def __random_corrupt__(\n",
        "        self,\n",
        "        x_in: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        # Randomly replaces input tokens by arbitrary tokens sampled either uniformly from the input vocabulary or according to\n",
        "        # the vocabulary distance function\n",
        "        # x_in : bs x max_len\n",
        "\n",
        "        if self.p_random_corruption == 0.:\n",
        "            return x_in\n",
        "\n",
        "        if (self.vocabulary.model == 'uniform'):\n",
        "            x_out = copy.deepcopy(x_in).to(x_in.device)\n",
        "            \n",
        "            for (b, i) in product(range(x_in.shape[0]), range(x_in.shape[1])):\n",
        "                if random.uniform(0, 1) < self.p_random_corruption:\n",
        "                    x_out[b, i] = random.randint(1, self.vocabulary.size)\n",
        "\n",
        "        elif (self.vocabulary.model == '1d'):\n",
        "            pass\n",
        "        \n",
        "        elif (self.vocabulary.model == 'chromatic'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == '2d'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'phoneme_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'keyboard_accurate'):\n",
        "            pass\n",
        "\n",
        "        elif (self.vocabulary.model == 'tree_hierarchical'):\n",
        "            pass\n",
        "        \n",
        "        return x_out\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x_in: torch.Tensor,\n",
        "        order=['insertion', 'deletion', 'permutation', 'corruption'],\n",
        "    ) -> torch.Tensor:\n",
        "        methods = {\n",
        "            'insertion': self.__random_insert__,\n",
        "            'deletion': self.__random_delete__,\n",
        "            'permutation': self.__random_permute__,\n",
        "            'corruption': self.__random_corrupt__,\n",
        "        }\n",
        "\n",
        "        # loss, _ = self.vocabulary.compute_cost(x_in)\n",
        "\n",
        "        for op in order:\n",
        "            x_in = methods[op](x_in)\n",
        "\n",
        "        x_0 = torch.zeros((x_in.shape[0], 1)).to(x_in.device)\n",
        "        x_out = torch.cat((x_in, x_0,), dim=1)\n",
        "\n",
        "        return x_in #, loss\n",
        "\n",
        "channel = Channel(\n",
        "    p_random_insertion=0.05,\n",
        "    p_random_deletion=0.05,\n",
        "    p_random_permutation=0.05,\n",
        "    p_random_corruption=0.05,\n",
        ")\n",
        "\n",
        "__x_out_insert__ = channel.__random_insert__(__x_in__)\n",
        "print(\"\\nVisualizing the effect of channel noisyness wrt. random insertions :\")\n",
        "visualize_batch_communication(__x_in__, __x_out_insert__)\n",
        "\n",
        "__x_out_delete__ = channel.__random_delete__(__x_in__)\n",
        "print(\"\\n\\nVisualizing the effect of channel noisyness wrt. random deletions :\")\n",
        "visualize_batch_communication(__x_in__, __x_out_delete__)\n",
        "\n",
        "__x_out_permute__ = channel.__random_permute__(__x_in__)\n",
        "print(\"\\n\\nVisualizing the effect of channel noisyness wrt. random permutations :\")\n",
        "visualize_batch_communication(__x_in__, __x_out_permute__)\n",
        "\n",
        "__x_out_corrupt__ = channel.__random_corrupt__(__x_in__)\n",
        "print(\"\\n\\nVisualizing the effect of channel noisyness wrt. random token-level corruptions :\")\n",
        "visualize_batch_communication(__x_in__, __x_out_corrupt__)\n",
        "\n",
        "__x_out_full__ = channel.forward(\n",
        "    __x_in__,\n",
        "    order=['insertion', 'deletion', 'permutation', 'corruption'],\n",
        ")\n",
        "print(\"\\n\\nVisualizing the effect of full channel corruption (insertion -> deletion -> permutation -> corruption in that order) :\")\n",
        "visualize_batch_communication(__x_in__, __x_out_full__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW5XggXCsGHo"
      },
      "source": [
        "---\n",
        "# 4. 🏋 Training routine 🏋\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBExGc73sViT"
      },
      "source": [
        "## A. 🔦 Defining the hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3qAVxKczSSy"
      },
      "source": [
        "#### **Vision model** related parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XryVYE4szWJB"
      },
      "outputs": [],
      "source": [
        "mp = {\n",
        "    'model_name': 'resnet-50',\n",
        "    'dataset': 'mnist', # 'tiny-imagenet', etc...\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Pa4YoSzWjc"
      },
      "source": [
        "#### **General-purpose** parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7E6yZ6CzWEX"
      },
      "outputs": [],
      "source": [
        "gp = {\n",
        "    'random_seed': 42,\n",
        "    'num_epochs': 5,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWN9knS3zW5l"
      },
      "source": [
        "#### **Sender** parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE-Ziyy8zV-f"
      },
      "outputs": [],
      "source": [
        "sp = {\n",
        "    's_hidden_sizes': [400],\n",
        "\n",
        "    's_hidden_size': 20, \n",
        "    's_emb_size': 10,\n",
        "    's_cell': 'gru', # 'lstm', 'rnn', 'gru'\n",
        "    's_entropy_coeff': 0.015,\n",
        "    's_num_layers': 1,\n",
        "    's_lr': 1e-3, # as a rule of thumb, should be lower than the learning rate of the rp\n",
        "\n",
        "    's_lr_scheduler_mult': 2,\n",
        "    's_lr_scheduler_eta_min': 0.01,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ej-Z4YTzXH5"
      },
      "source": [
        "#### **Vocabulary**-level parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjLCtXJVzV4q"
      },
      "outputs": [],
      "source": [
        "vp = {\n",
        "    'vocab_size': 10,\n",
        "    'vocab_model': 'uniform',\n",
        "    'vocab_loss_c': None,\n",
        "    'vocab_loss_mute': None,\n",
        "    'vocab_mu_dist': None,\n",
        "    'vocab_temperature': None,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP6w20XGzXXh"
      },
      "source": [
        "#### **Channel**-level parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQWhb7nYzVy2"
      },
      "outputs": [],
      "source": [
        "cp = {\n",
        "    'max_len': 5,\n",
        "    'channel_top_k': None,\n",
        "    'channel_temperature': None,\n",
        "    'p_random_insertion': 0.05,\n",
        "    'p_random_deletion': 0.05,\n",
        "    'p_random_permutation': 0.05,\n",
        "    'p_random_corruption': 0.05,\n",
        "    'corruption_function': ['insertion', 'deletion', 'permutation', 'corruption'],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HqIUc3qzXsH"
      },
      "source": [
        "#### **Receiver** parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVTh_PwMzVtD"
      },
      "outputs": [],
      "source": [
        "rp = {\n",
        "    'r_hidden_sizes': [400],\n",
        "\n",
        "    'r_hidden_size': 20, \n",
        "    'r_emb_size': 10,\n",
        "    'r_cell': 'gru', # 'lstm', 'rnn', 'gru'\n",
        "    'r_entropy_coeff': 0.0,\n",
        "    'r_num_layers': 1,\n",
        "    'r_lr': 1e-2,\n",
        "\n",
        "    'r_lr_scheduler_mult': 3,\n",
        "    'r_lr_scheduler_eta_min': 0.01,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDqiyjLCzYJC"
      },
      "source": [
        "#### **Optimization**-related parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6izgoKqHzU82"
      },
      "outputs": [],
      "source": [
        "op = {\n",
        "    'n_epochs': 5,\n",
        "    'grad_norm': 0,\n",
        "    'temperature_decay': 0.75,\n",
        "    'temperature_minimum': 0.01,\n",
        "    'temperature_update_freq': 1,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMZKFJPizYaO"
      },
      "source": [
        "#### **Task**-related parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8omBEnmsYrx"
      },
      "outputs": [],
      "source": [
        "tp = {\n",
        "    'task_loss': ('reconstruction', loss_bce_reconstruction, 'bce'),\n",
        "    # ('discrimination', loss_nll_discrimination, 'nll')\n",
        "    # ('discrimination', loss_accuracy_discrimination, 'accuracy')\n",
        "    # ('discrimination', loss_bce_reconstruction, 'bce')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Z38eAw2abP"
      },
      "source": [
        "#### **Callbacks**-related parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4th7NMNk2atP"
      },
      "outputs": [],
      "source": [
        "cap = {\n",
        "    'checkpoint_freq': 1,\n",
        "    'max_checkpoints': 5,\n",
        "    'early_stopping_field': 'acc',\n",
        "    'early_stopping_threshold': 0.2,\n",
        "    'all_distances_topsim': True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di3-U2Ftz3tb"
      },
      "outputs": [],
      "source": [
        "# We will later push the experiment's hyperparameters to Weights & Biases in order to keep track of them\n",
        "params = {**mp, **gp, **sp, **vp, **cp, **rp, **op, **tp, **cap}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-NkaLQg1H2F"
      },
      "outputs": [],
      "source": [
        "if params['task_loss'][0] == 'reconstruction':\n",
        "    WANDB_EXPERIMENT_GROUP = 'reconstruction-game'\n",
        "elif params['task_loss'][0] == 'discrimination':\n",
        "    WANDB_EXPERIMENT_GROUP = 'discrimination-game'\n",
        "else:\n",
        "    WANDB_EXPERIMENT_GROUP = 'ablation-study'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do6YQc8rsb5U"
      },
      "source": [
        "## B. ⏭ Instantiating the agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4zZ5_P-FsoX"
      },
      "source": [
        "#### 🔍 Utility function to load the best checkpoint of a vision module finetuned in an other notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U8yM5R9GAW3"
      },
      "outputs": [],
      "source": [
        "def retrieve_finetuned_vision_model(\n",
        "    model_name, \n",
        "    dataset, \n",
        "    add_name=None,\n",
        "):\n",
        "    if add_name is None:\n",
        "        NAME_RUN = f'Vision model pretraining : M[{model_name}], D[{dataset}]'\n",
        "        NAME_CHECKPOINT = f'model={model_name}_dataset={dataset}'\n",
        "    else:\n",
        "        NAME_RUN = f'Vision model pretraining : M[{model_name}], D[{dataset}], D[{add_name}]'\n",
        "        NAME_CHECKPOINT = f'model={model_name}_dataset={dataset}_cond={model_name}'\n",
        "\n",
        "    DIR_CHECKPOINT = FINETUNED_MODELS_DIR + NAME_CHECKPOINT + '/'\n",
        "\n",
        "    print(f'Loading the model {model_name} finetuned on the dataset {dataset} ...')\n",
        "\n",
        "    def find_best_epoch(\n",
        "        ckpt_folder,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Find the highest epoch in the Test Tube file structure.\n",
        "        :param ckpt_folder: dir where the checkpoints are being saved.\n",
        "        :return: Integer of the highest epoch reached by the checkpoints.\n",
        "        \"\"\"\n",
        "        checkpoint_files = os.listdir(ckpt_folder)  # list of strings\n",
        "        accuracies = [re.search('val_accuracy=(.*).pt', filename) for filename in checkpoint_files]\n",
        "        checkpoint_files = list(filter(lambda x: x[1] is not None, list(zip(checkpoint_files, accuracies))))\n",
        "        checkpoint_files = map(lambda x : (x[0], x[1].group(1),), checkpoint_files)\n",
        "        best_checkpoint_filename, best_accuracy = max(checkpoint_files, key=itemgetter(1))\n",
        "        print(f'Found the following checkpoint : {best_checkpoint_filename} with the following validation accuracy : {best_accuracy}')\n",
        "\n",
        "        return best_checkpoint_filename\n",
        "\n",
        "    best_checkpoint_filepath = find_best_epoch(DIR_CHECKPOINT)\n",
        "    full_checkpoint_filepath = DIR_CHECKPOINT + best_checkpoint_filepath\n",
        "\n",
        "    # Retrieving the general vision model architecture (without the finetuned weights)\n",
        "    __model_backbone__, dim_vision_out = get_vision_module(version=model_name)\n",
        "\n",
        "    # Loading the finetuned weights of the vision model into the backbone architecture\n",
        "    if torch.cuda.is_available():\n",
        "        __model_backbone__.load_state_dict(torch.load(\n",
        "            full_checkpoint_filepath,\n",
        "        ))\n",
        "    else:\n",
        "        __model_backbone__.load_state_dict(torch.load(\n",
        "            full_checkpoint_filepath,\n",
        "            map_location=torch.device('cpu'),\n",
        "        ))\n",
        "\n",
        "    # __model_backbone__.fc = nn.Identity()\n",
        "\n",
        "    print(f'Successfully loaded the model {model_name} finetuned on the dataset {dataset} ...')\n",
        "\n",
        "    return __model_backbone__, dim_vision_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFst8JATF2ns"
      },
      "source": [
        "#### Instantiating the general architecture of the vision model's optimizer + prediction layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1rFHmuARtbP"
      },
      "outputs": [],
      "source": [
        "# model, dim_vision_out = get_vision_module(version=params['model_name'])\n",
        "\n",
        "# model, dim_vision_out = retrieve_finetuned_vision_model(params['model_name'], params['dataset'], add_name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy_jmKMew8eZ"
      },
      "outputs": [],
      "source": [
        "dim_vision_out = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRuWXMVn78Cm"
      },
      "outputs": [],
      "source": [
        "# !ls \"/content/drive/My Drive/Projects/nlp_emergent_languages/finetuned_models/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX7Vlvm4zjzu"
      },
      "source": [
        "#### Creating the stochastic image transformation operators (*data augmentation*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CzLqKEkyF9U"
      },
      "outputs": [],
      "source": [
        "# multi_channel = not params['dataset'] in ['mnist', 'k-mnist', 'q-mnist', 'fashion-mnist']\n",
        "# transform_train = TransformsAugment(size=sizes[params['dataset']], multi_channel=multi_channel)\n",
        "# transform_val_test = TransformsAugment(size=sizes[params['dataset']], multi_channel=multi_channel)\n",
        "# transform_train = T.Compose([T.ToTensor(), T.Lambda(lambda x: x.repeat(3,1,1))])\n",
        "# transform_val_test = T.Compose([T.ToTensor(), T.Lambda(lambda x: x.repeat(3,1,1))])\n",
        "transform_train, transform_val_test = T.ToTensor(), T.ToTensor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpuUaw4c0xds"
      },
      "source": [
        "#### Loading the dataset on which the model was finetuned (and which will be used in order to train the agents on a reconstruction task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AwfCxSTzpWL"
      },
      "outputs": [],
      "source": [
        "split = image_datasets[params['dataset']](\n",
        "    transform_train, \n",
        "    transform_val_test,\n",
        ")\n",
        "train_loader, val_loader, test_loader = split.values()\n",
        "NUM_CHANNELS = n_channels[params['dataset']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcm2IWVfGEPK"
      },
      "source": [
        "#### Creating the **vocabulary model** and the **noisy communication channel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqR8m2PeGJ5e"
      },
      "outputs": [],
      "source": [
        "VOCAB = Vocabulary(\n",
        "    vocab_model=params['vocab_model'],\n",
        "    vocab_size=params['vocab_size'],\n",
        "    vocab_loss_c=params['vocab_loss_c'],\n",
        "    vocab_loss_mute=params['vocab_loss_mute'],\n",
        "    vocab_mu_dist=params['vocab_mu_dist'],\n",
        "    vocab_temperature=params['vocab_temperature'],\n",
        ")\n",
        "\n",
        "CHANNEL = Channel(\n",
        "    max_len=params['max_len'],\n",
        "    channel_top_k=params['channel_top_k'],\n",
        "    channel_temperature=params['channel_temperature'],\n",
        "    vocabulary=VOCAB,\n",
        "    p_random_insertion=params['p_random_insertion'],\n",
        "    p_random_deletion=params['p_random_deletion'],\n",
        "    p_random_permutation=params['p_random_permutation'],\n",
        "    p_random_corruption=params['p_random_corruption'],\n",
        "    corruption_function=params['corruption_function'],   \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYFScO1FMbx_"
      },
      "source": [
        "#### Instantiating a new channel communication wrapper taking into account our custom modification of the **Vocabulary** and **Channel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hk_h3kpwuJgz"
      },
      "outputs": [],
      "source": [
        "import egg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmPQb06uMh_F"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "from egg.core.baselines import Baseline, MeanBaseline\n",
        "from typing import Callable\n",
        "from egg.core.baselines import Baseline, MeanBaseline\n",
        "from egg.core.interaction import LoggingStrategy\n",
        "from egg.core.rnn import RnnEncoder\n",
        "from egg.core.transformer import TransformerDecoder, TransformerEncoder\n",
        "from egg.core.util import find_lengths\n",
        "\n",
        "class SenderReceiverRnnReinforce(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Sender/Receiver game with training done via Reinforce. Both agents are supposed to\n",
        "    return 3-tuples of (output, log-prob of the output, entropy).\n",
        "    The game implementation is responsible for handling the end-of-sequence term, so that the optimized loss\n",
        "    corresponds either to the position of the eos term (assumed to be 0) or the end of sequence.\n",
        "    Sender and Receiver can be obtained by applying the corresponding wrappers.\n",
        "    `SenderReceiverRnnReinforce` also applies the mean baseline to the loss function to reduce\n",
        "    the variance of the gradient estimate.\n",
        "    >>> class Sender(nn.Module):\n",
        "    ...     def __init__(self):\n",
        "    ...         super().__init__()\n",
        "    ...         self.fc = nn.Linear(3, 10)\n",
        "    ...     def forward(self, rnn_output, _input=None, _aux_input=None):\n",
        "    ...         return self.fc(rnn_output)\n",
        "    >>> sender = Sender()\n",
        "    >>> sender = RnnSenderReinforce(sender, vocab_size=15, embed_dim=5, hidden_size=10, max_len=10, cell='lstm')\n",
        "    >>> class Receiver(nn.Module):\n",
        "    ...     def __init__(self):\n",
        "    ...         super().__init__()\n",
        "    ...         self.fc = nn.Linear(5, 3)\n",
        "    ...     def forward(self, rnn_output, _input=None, _aux_input=None):\n",
        "    ...         return self.fc(rnn_output)\n",
        "    >>> receiver = RnnReceiverDeterministic(Receiver(), vocab_size=15, embed_dim=10, hidden_size=5)\n",
        "    >>> def loss(sender_input, _message, _receiver_input, receiver_output, _labels, _aux_input):\n",
        "    ...     loss = F.mse_loss(sender_input, receiver_output, reduction='none').mean(dim=1)\n",
        "    ...     aux = {'aux': torch.ones(sender_input.size(0))}\n",
        "    ...     return loss, aux\n",
        "    >>> game = SenderReceiverRnnReinforce(sender, receiver, loss, sender_entropy_coeff=0.0, receiver_entropy_coeff=0.0,\n",
        "    ...                                   length_cost=1e-2)\n",
        "    >>> input = torch.zeros((5, 3)).normal_()\n",
        "    >>> optimized_loss, interaction = game(input, labels=None, aux_input=None)\n",
        "    >>> sorted(list(interaction.aux.keys()))  # returns debug info such as entropies of the agents, message length etc\n",
        "    ['aux', 'length', 'receiver_entropy', 'sender_entropy']\n",
        "    >>> interaction.aux['aux'], interaction.aux['aux'].sum()\n",
        "    (tensor([1., 1., 1., 1., 1.]), tensor(5.))\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sender: nn.Module,\n",
        "        receiver: nn.Module,\n",
        "        loss: Callable,\n",
        "        sender_entropy_coeff: float = 0.0,\n",
        "        receiver_entropy_coeff: float = 0.0,\n",
        "        length_cost: float = 0.0,\n",
        "        baseline_type: Baseline = MeanBaseline,\n",
        "        train_logging_strategy: LoggingStrategy = None,\n",
        "        test_logging_strategy: LoggingStrategy = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param sender: sender agent\n",
        "        :param receiver: receiver agent\n",
        "        :param loss:  the optimized loss that accepts\n",
        "            sender_input: input of Sender\n",
        "            message: the is sent by Sender\n",
        "            receiver_input: input of Receiver from the dataset\n",
        "            receiver_output: output of Receiver\n",
        "            labels: labels assigned to Sender's input data\n",
        "          and outputs a tuple of (1) a loss tensor of shape (batch size, 1) (2) the dict with auxiliary information\n",
        "          of the same shape. The loss will be minimized during training, and the auxiliary information aggregated over\n",
        "          all batches in the dataset.\n",
        "        :param sender_entropy_coeff: entropy regularization coeff for sender\n",
        "        :param receiver_entropy_coeff: entropy regularization coeff for receiver\n",
        "        :param length_cost: the penalty applied to Sender for each symbol produced\n",
        "        :param baseline_type: Callable, returns a baseline instance (eg a class specializing core.baselines.Baseline)\n",
        "        :param train_logging_strategy, test_logging_strategy: specify what parts of interactions to persist for\n",
        "            later analysis in callbacks\n",
        "        \"\"\"\n",
        "        super(SenderReceiverRnnReinforce, self).__init__()\n",
        "        self.sender = sender\n",
        "        self.receiver = receiver\n",
        "        self.loss = loss\n",
        "\n",
        "        self.mechanics = CommunicationRnnReinforce(\n",
        "            sender_entropy_coeff,\n",
        "            receiver_entropy_coeff,\n",
        "            length_cost,\n",
        "            baseline_type,\n",
        "            train_logging_strategy,\n",
        "            test_logging_strategy,\n",
        "        )\n",
        "\n",
        "    def forward(self, sender_input, labels, receiver_input=None, aux_input=None):\n",
        "        return self.mechanics(\n",
        "            self.sender,\n",
        "            self.receiver,\n",
        "            self.loss,\n",
        "            sender_input,\n",
        "            labels,\n",
        "            receiver_input,\n",
        "            aux_input,\n",
        "        )\n",
        "\n",
        "\n",
        "class CommunicationRnnReinforce(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        sender_entropy_coeff: float,\n",
        "        receiver_entropy_coeff: float,\n",
        "        length_cost: float = 0.0,\n",
        "        baseline_type: Baseline = MeanBaseline,\n",
        "        train_logging_strategy: LoggingStrategy = None,\n",
        "        test_logging_strategy: LoggingStrategy = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param sender_entropy_coeff: entropy regularization coeff for sender\n",
        "        :param receiver_entropy_coeff: entropy regularization coeff for receiver\n",
        "        :param length_cost: the penalty applied to Sender for each symbol produced\n",
        "        :param baseline_type: Callable, returns a baseline instance (eg a class specializing core.baselines.Baseline)\n",
        "        :param train_logging_strategy, test_logging_strategy: specify what parts of interactions to persist for\n",
        "            later analysis in callbacks\n",
        "        \"\"\"\n",
        "\n",
        "        global CHANNEL\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.sender_entropy_coeff = sender_entropy_coeff\n",
        "        self.receiver_entropy_coeff = receiver_entropy_coeff\n",
        "        self.length_cost = length_cost\n",
        "\n",
        "        self.baselines = defaultdict(baseline_type)\n",
        "        self.train_logging_strategy = (\n",
        "            LoggingStrategy()\n",
        "            if train_logging_strategy is None\n",
        "            else train_logging_strategy\n",
        "        )\n",
        "        self.test_logging_strategy = (\n",
        "            LoggingStrategy()\n",
        "            if test_logging_strategy is None\n",
        "            else test_logging_strategy\n",
        "        )\n",
        "\n",
        "        self.said = False\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        sender,\n",
        "        receiver,\n",
        "        loss,\n",
        "        sender_input,\n",
        "        labels,\n",
        "        receiver_input=None,\n",
        "        aux_input=None,\n",
        "    ):\n",
        "        global CHANNEL\n",
        "\n",
        "        if not self.said:\n",
        "            print(\"==============================================\")\n",
        "            print(\"PROOF THAT CHANNEL HYPERPARAMETERS ARE UPDATED\")\n",
        "            print(f\"P Random Insertion : {CHANNEL.p_random_insertion}\")\n",
        "            print(f\"P Random Deletion : {CHANNEL.p_random_deletion}\")\n",
        "            print(f\"P Random Permutation : {CHANNEL.p_random_permutation}\")\n",
        "            print(f\"P Random Corruption : {CHANNEL.p_random_corruption}\")\n",
        "            print(f\"Corruption function : {CHANNEL.corruption_function}\")\n",
        "            print(f\"Max Len : {CHANNEL.max_len}\")\n",
        "            print(\"==============================================\")\n",
        "            self.said = True\n",
        "        \n",
        "        message, log_prob_s, entropy_s = sender(sender_input, aux_input)\n",
        "\n",
        "        # print(message)\n",
        "        # print(message.shape)\n",
        "        # print(interaction.message)\n",
        "        # print(message, message.device, message.shape, message.type())\n",
        "        new_message = CHANNEL.forward(message).long()\n",
        "        # print(new_message, new_message.device, new_message.shape, new_message.type())\n",
        "\n",
        "        message_length = find_lengths(message)\n",
        "        receiver_output, log_prob_r, entropy_r = receiver(\n",
        "            message, receiver_input, aux_input, message_length\n",
        "        )\n",
        "\n",
        "        loss, aux_info = loss(\n",
        "            sender_input, message, receiver_input, receiver_output, labels, aux_input\n",
        "        )\n",
        "\n",
        "        # the entropy of the outputs of S before and including the eos symbol - as we don't care about what's after\n",
        "        effective_entropy_s = torch.zeros_like(entropy_r)\n",
        "\n",
        "        # the log prob of the choices made by S before and including the eos symbol - again, we don't\n",
        "        # care about the rest\n",
        "        effective_log_prob_s = torch.zeros_like(log_prob_r)\n",
        "\n",
        "        for i in range(message.size(1)):\n",
        "            not_eosed = (i < message_length).float()\n",
        "            effective_entropy_s += entropy_s[:, i] * not_eosed\n",
        "            effective_log_prob_s += log_prob_s[:, i] * not_eosed\n",
        "        effective_entropy_s = effective_entropy_s / message_length.float()\n",
        "\n",
        "        weighted_entropy = (\n",
        "            effective_entropy_s.mean() * self.sender_entropy_coeff\n",
        "            + entropy_r.mean() * self.receiver_entropy_coeff\n",
        "        )\n",
        "\n",
        "        log_prob = effective_log_prob_s + log_prob_r\n",
        "\n",
        "        length_loss = message_length.float() * self.length_cost\n",
        "\n",
        "        policy_length_loss = (\n",
        "            (length_loss - self.baselines[\"length\"].predict(length_loss))\n",
        "            * effective_log_prob_s\n",
        "        ).mean()\n",
        "        policy_loss = (\n",
        "            (loss.detach() - self.baselines[\"loss\"].predict(loss.detach())) * log_prob\n",
        "        ).mean()\n",
        "\n",
        "        optimized_loss = policy_length_loss + policy_loss - weighted_entropy\n",
        "        # if the receiver is deterministic/differentiable, we apply the actual loss\n",
        "        optimized_loss += loss.mean()\n",
        "\n",
        "        if self.training:\n",
        "            self.baselines[\"loss\"].update(loss)\n",
        "            self.baselines[\"length\"].update(length_loss)\n",
        "\n",
        "        aux_info[\"sender_entropy\"] = entropy_s.detach()\n",
        "        aux_info[\"receiver_entropy\"] = entropy_r.detach()\n",
        "        aux_info[\"length\"] = message_length.float()  # will be averaged\n",
        "\n",
        "        logging_strategy = (\n",
        "            self.train_logging_strategy if self.training else self.test_logging_strategy\n",
        "        )\n",
        "        interaction = logging_strategy.filtered_interaction(\n",
        "            sender_input=sender_input,\n",
        "            labels=labels,\n",
        "            receiver_input=receiver_input,\n",
        "            aux_input=aux_input,\n",
        "            message=message.detach(),\n",
        "            receiver_output=receiver_output.detach(),\n",
        "            message_length=message_length,\n",
        "            aux=aux_info,\n",
        "        )\n",
        "\n",
        "        return optimized_loss, interaction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0QPcaICGB_7"
      },
      "source": [
        "#### Instantiating the agent's modules building up on the vision module defined above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA2neTdasGYb"
      },
      "outputs": [],
      "source": [
        "# Sender / receiver models responsible respectively for producing / processing the initial / final RNN hidden state\n",
        "sender = Sender(\n",
        "    vision, \n",
        "    input_size=dim_vision_out, \n",
        "    output_size=params['s_hidden_size'], \n",
        "    hidden_sizes=params['s_hidden_sizes'],\n",
        ")\n",
        "receiver = Receiver(\n",
        "    input_size=params['r_hidden_size'], \n",
        "    output_size=int(sizes[params['dataset']] ** 2),\n",
        "    hidden_sizes=params['r_hidden_sizes'],\n",
        ")\n",
        "\n",
        "# Wrapping the sender / receiver models into a RNN module in order to handle variable-length messages\n",
        "sender_rnn = core.RnnSenderReinforce(\n",
        "    agent=sender, \n",
        "    vocab_size=params['vocab_size'], \n",
        "    embed_dim=params['s_emb_size'], \n",
        "    hidden_size=params['s_hidden_size'], \n",
        "    cell=params['s_cell'], \n",
        "    max_len=params['max_len'], \n",
        "    num_layers=params['s_num_layers'],\n",
        ")\n",
        "receiver_rnn = core.RnnReceiverDeterministic(\n",
        "    agent=receiver, \n",
        "    vocab_size=params['vocab_size'], \n",
        "    embed_dim=params['r_emb_size'], \n",
        "    hidden_size=params['r_hidden_size'], \n",
        "    cell=params['r_cell'], \n",
        "    num_layers=params['r_num_layers'],\n",
        ")\n",
        "\n",
        "# Initializing the game wrapper module\n",
        "game_rnn = SenderReceiverRnnReinforce(sender_rnn, receiver_rnn, params['task_loss'][1], sender_entropy_coeff=params['s_entropy_coeff'], receiver_entropy_coeff=params['r_entropy_coeff'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcghX-ZUbuvS"
      },
      "source": [
        "## C. ⚓ Helper functions and callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQpwC2JC0T4e"
      },
      "source": [
        "### Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5dshAKm0TH1"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    temperature_updater_callback = core.TemperatureUpdater(\n",
        "        agent=sender, \n",
        "        decay=params['temperature_decay'], \n",
        "        minimum=params['temperature_minimum'],\n",
        "        update_frequency=params['temperature_update_freq'],\n",
        "    )\n",
        "\n",
        "early_stopping_callback = core.EarlyStopperAccuracy(\n",
        "    threshold=params['early_stopping_threshold'],\n",
        "    field_name=params['early_stopping_field'],\n",
        "    validation=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RxWnZID0XAf"
      },
      "source": [
        "### Checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqV6qXuV9BTs"
      },
      "outputs": [],
      "source": [
        "NAME_CHECKPOINT = f\"game={params['task_loss'][0]}_model={params['model_name']}_dataset={params['dataset']}_\"\n",
        "SUB_DIRECTORY = WANDB_EXPERIMENT_GROUP + '/'\n",
        "CHECKPOINT_DIR = CHECKPOINTS_DIR + SUB_DIRECTORY + NAME_CHECKPOINT + '/'\n",
        "\n",
        "INTERACTION_DIR = INTERACTIONS_DIR + WANDB_EXPERIMENT_GROUP + '/' + NAME_CHECKPOINT + '/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q8Mmy6N0TBC"
      },
      "outputs": [],
      "source": [
        "checkpoint_saver_callback = core.CheckpointSaver(\n",
        "    checkpoint_path=CHECKPOINT_DIR,\n",
        "    checkpoint_freq=params['checkpoint_freq'],\n",
        "    prefix=NAME_CHECKPOINT,\n",
        "    max_checkpoints=params['max_checkpoints'],\n",
        ")\n",
        "\n",
        "interaction_saver_callback = core.InteractionSaver(\n",
        "    train_epochs=list(range(1, params['num_epochs'] + 1, 2)),\n",
        "    test_epochs=list(range(2, params['num_epochs'] + 1, 2)),\n",
        "    checkpoint_dir=INTERACTION_DIR,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pgsH1ZZ0YnY"
      },
      "source": [
        "### Display and ML experiment management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQuFrG4EQZEg"
      },
      "outputs": [],
      "source": [
        "def wandb_connect():\n",
        "    wandb_conx = wandb.login(key = WANDB_API_KEY)\n",
        "    print(f\"Connected to Wandb online interface : {wandb_conx}\")\n",
        "\n",
        "LOG_WANDB = True\n",
        "\n",
        "if LOG_WANDB:\n",
        "    wandb_connect()\n",
        "\n",
        "    WANDB_RUN = wandb.init(\n",
        "        project=WANDB_PROJECT, \n",
        "        entity=WANDB_ENTITY,\n",
        "        notes=WANDB_NOTES,\n",
        "        name=WANDB_EXPERIMENT_NAME,\n",
        "        group=WANDB_EXPERIMENT_GROUP,\n",
        "        save_code=True,\n",
        "    )\n",
        "\n",
        "    WANDB_RUN_ID = WANDB_RUN.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neLOYYBJbu_s"
      },
      "outputs": [],
      "source": [
        "if LOG_WANDB:\n",
        "    wandb_logger = core.callbacks.WandbLogger(\n",
        "        opts=params,\n",
        "        project=WANDB_PROJECT,\n",
        "        run_id=WANDB_RUN_ID,\n",
        "    )\n",
        "\n",
        "    console_logger_callback = core.callbacks.ConsoleLogger(\n",
        "        as_json=False, \n",
        "        print_train_loss=True,\n",
        "    )\n",
        "\n",
        "    progress_bar_callback = core.callbacks.ProgressBarLogger(\n",
        "        n_epochs=params['n_epochs'], \n",
        "        use_info_table=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeMmjzxC1IuU"
      },
      "source": [
        "### Linguistic analysis metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V31vLGXWvw1P"
      },
      "outputs": [],
      "source": [
        "distances = ['edit', 'cosine', 'hamming', 'jaccard', 'euclidean']\n",
        "if params['all_distances_topsim']:\n",
        "    distances_topsim = product(distances, distances)\n",
        "else:\n",
        "    distances_topsim = [('hamming', 'edit')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvnd-oDh1K0q"
      },
      "outputs": [],
      "source": [
        "disentanglement_metric_callback = core.Disent(\n",
        "    is_gumbel=False,\n",
        "    compute_posdis=True,\n",
        "    compute_bosdis=True,\n",
        "    vocab_size=params['vocab_size'],\n",
        "    print_train=True,\n",
        "    print_test=True,\n",
        ")\n",
        "\n",
        "topographic_similarity_metric_callbacks = [core.TopographicSimilarity(\n",
        "    sender_input_distance_fn=input_dist,\n",
        "    message_distance_fn=message_dist,\n",
        "    compute_topsim_train_set=True,\n",
        "    compute_topsim_test_set=True,\n",
        "    is_gumbel=False,) for (input_dist, message_dist) in distances_topsim]\n",
        "\n",
        "message_entropy_metric_callback = core.MessageEntropy(\n",
        "    print_train=True,\n",
        "    is_gumbel=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGJclYzp7ESi"
      },
      "source": [
        "### Gathering active callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vULLpogK6po_"
      },
      "outputs": [],
      "source": [
        "callbacks=[\n",
        "           # temperature_updater_callback,\n",
        "           early_stopping_callback,\n",
        "           \n",
        "           checkpoint_saver_callback,\n",
        "           interaction_saver_callback,\n",
        "           \n",
        "           # wandb_logger,\n",
        "           # console_logger_callback,\n",
        "           # progress_bar_callback,\n",
        "\n",
        "           # disentanglement_metric_callback,\n",
        "           message_entropy_metric_callback,\n",
        "          ]\n",
        "          \n",
        "if LOG_WANDB:\n",
        "    callbacks.append(wandb_logger)\n",
        "    callbacks.append(console_logger_callback)\n",
        "    callbacks.append(progress_bar_callback)\n",
        "# callbacks += topographic_similarity_metric_callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oKmChOtscck"
      },
      "source": [
        "## D. 🚠 Defining the training routine and optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz9TbmVnscs_"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([\n",
        "        {'params': game_rnn.sender.parameters(), # Sender-side optimization hyperparameters\n",
        "         'lr': params['s_lr'],\n",
        "         # 'lr_scheduler': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=params['s_lr_scheduler_mult'], eta_min=params['s_lr_scheduler_eta_min'], last_epoch=-1),\n",
        "         },\n",
        "        {'params': game_rnn.receiver.parameters(), # Receiver-side optimization hyperparameters\n",
        "         'lr': params['r_lr'],\n",
        "         # 'lr_scheduler': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=params['r_lr_scheduler_mult'], eta_min=params['r_lr_scheduler_eta_min'], last_epoch=-1),\n",
        "         },\n",
        "    ])\n",
        "\n",
        "trainer = core.Trainer(\n",
        "    game=game_rnn, \n",
        "    optimizer=optimizer, \n",
        "    train_data=train_loader, \n",
        "    validation_data=val_loader,\n",
        "    # grad_norm=params['grad_norm'],\n",
        "    device=device,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRiGUuINPeCy"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# ---------\n",
        "# ---\n",
        "# -\n",
        "# trainer.train(\n",
        "#     n_epochs=5,\n",
        "# )\n",
        "# core.close()\n",
        "# -\n",
        "# ---\n",
        "# ---------\n",
        "# ---------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6qQhJlQ4xpk"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhR4FXCUw6bj"
      },
      "source": [
        "## E. 📺 Instantiating a test dataset and visualization functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7so8R8vCwTd"
      },
      "outputs": [],
      "source": [
        "def init_vocab_channel(\n",
        "    noisy=False,\n",
        "):\n",
        "    global VOCAB, CHANNEL\n",
        "\n",
        "    print(f\"Initializing the vocabulary model and the communication channel ... noisy=[{noisy}]\")\n",
        "\n",
        "    if noisy:\n",
        "        VOCAB = Vocabulary(\n",
        "            vocab_model=params['vocab_model'],\n",
        "            vocab_size=params['vocab_size'],\n",
        "            vocab_loss_c=params['vocab_loss_c'],\n",
        "            vocab_loss_mute=params['vocab_loss_mute'],\n",
        "            vocab_mu_dist=params['vocab_mu_dist'],\n",
        "            vocab_temperature=params['vocab_temperature'],\n",
        "        )\n",
        "\n",
        "        CHANNEL = Channel(\n",
        "            max_len=params['max_len'],\n",
        "            channel_top_k=params['channel_top_k'],\n",
        "            channel_temperature=params['channel_temperature'],\n",
        "            vocabulary=VOCAB,\n",
        "            p_random_insertion=params['p_random_insertion'],\n",
        "            p_random_deletion=params['p_random_deletion'],\n",
        "            p_random_permutation=params['p_random_permutation'],\n",
        "            p_random_corruption=params['p_random_corruption'],\n",
        "            corruption_function=params['corruption_function'],   \n",
        "        )\n",
        "\n",
        "    else:\n",
        "        VOCAB = Vocabulary(\n",
        "            vocab_model='uniform',\n",
        "            vocab_size=params['vocab_size'],\n",
        "            vocab_loss_c=None,\n",
        "            vocab_loss_mute=None,\n",
        "            vocab_mu_dist=None,\n",
        "            vocab_temperature=None,\n",
        "        )\n",
        "\n",
        "        CHANNEL = CHANNEL = Channel(\n",
        "            max_len=params['max_len'],\n",
        "            channel_top_k=None,\n",
        "            channel_temperature=None,\n",
        "            vocabulary=VOCAB,\n",
        "            p_random_insertion=0.,\n",
        "            p_random_deletion=0.,\n",
        "            p_random_permutation=0.,\n",
        "            p_random_corruption=0.,\n",
        "            corruption_function=0.,   \n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy6yK70gxAsh"
      },
      "outputs": [],
      "source": [
        "def plot(game, \n",
        "         dataloader, \n",
        "         name_split='train', \n",
        "         noisy=False, \n",
        "         ablation=None,\n",
        "    ):\n",
        "    global INTERACTIONS_DIR\n",
        "\n",
        "    init_vocab_channel(noisy)\n",
        "    \n",
        "    print(f\"Currently generating reconstructed (i.e. autoencoded) images for all class representatives of the following split : [{name_split}]\")\n",
        "    x = next(iter(dataloader))\n",
        "\n",
        "    if ablation is None:\n",
        "        filename = INTERACTION_DIR + f'{name_split}_split_noisy_{noisy}_reconstruction'\n",
        "    else:\n",
        "        filename = ablation + f'{name_split}_split_noisy_{noisy}_reconstruction'\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "    test_inputs = []\n",
        "    for z in range(10):\n",
        "        print((x[1] == z).nonzero().shape)\n",
        "        try:\n",
        "            index = (x[1] == z).nonzero()[0, 0]\n",
        "            img = x[0][index]\n",
        "            test_inputs.append(img.unsqueeze(0))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    test_inputs = torch.cat(test_inputs)\n",
        "\n",
        "    by_class_dataset = [[test_inputs, None]]\n",
        "\n",
        "    interaction = core.dump_interactions(game, by_class_dataset, False, variable_length=True)\n",
        "\n",
        "    for z in range(len(test_inputs)):\n",
        "        src = interaction.sender_input[z].squeeze(0)[:, :]\n",
        "        print(src.shape)\n",
        "        dst = interaction.receiver_output[z].view(src.shape[1], src.shape[1])\n",
        "        # we'll plot two images side-by-side: the original (left) and the reconstruction\n",
        "        # print(dst.shape)\n",
        "        image = torch.cat([src[:, :], dst], dim=1).cpu().numpy()\n",
        "\n",
        "        plt.title(f\"Input: digit {z}, channel message {interaction.message[z]}\")\n",
        "        plt.imshow(image[:, :], cmap='gray')\n",
        "        plt.savefig(filename + '_image_{z}.png')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JxuPLK2TlYT"
      },
      "outputs": [],
      "source": [
        "# plot(game_rnn, train_loader, name_split='train', noisy=False, ablation=None)\n",
        "# plot(game_rnn, train_loader, name_split='train', noisy=True, ablation=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMFRf9ipTlQr"
      },
      "outputs": [],
      "source": [
        "# plot(game_rnn, val_loader, name_split='val', noisy=False, ablation=None)\n",
        "# plot(game_rnn, val_loader, name_split='val', noisy=True, ablation=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7FANZQWTlFZ"
      },
      "outputs": [],
      "source": [
        "# plot(game_rnn, test_loader, name_split='test', noisy=False, ablation=None)\n",
        "# plot(game_rnn, test_loader, name_split='test', noisy=True, ablation=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7Oe9Ct8TdeF"
      },
      "outputs": [],
      "source": [
        "def generate_interactions(\n",
        "    game, \n",
        "    dataloader, \n",
        "    name_split='train', \n",
        "    noisy=False, \n",
        "    ablation=None,\n",
        "    until=None\n",
        "):\n",
        "    global INTERACTIONS_DIR\n",
        "\n",
        "    init_vocab_channel(noisy)\n",
        "\n",
        "    def dump_to_csv(data, name_data='messages_tokenized'):\n",
        "        if ablation is None:\n",
        "            filename = INTERACTION_DIR + f'{name_split}_split_noisy_{noisy}.csv'\n",
        "        else:\n",
        "            filename = ablation + f'{name_split}_split_noisy_{noisy}.csv'\n",
        "        print(filename)\n",
        "        os.makedirs(os.path.dirname(filename), exist_ok=True) # We first create the required directory to dump the interactions\n",
        "        # if it does not exist yet\n",
        "        file = open(filename, 'w+', newline ='')\n",
        "        with file:    \n",
        "            write = csv.writer(file)\n",
        "            write.writerows(data)\n",
        "\n",
        "    print(f\"Currently generating batches of textual interactions for the following split : [{name_split}]\")\n",
        "\n",
        "    __messages__ = []\n",
        "\n",
        "    if (until is None) or (until > len(dataloader)):\n",
        "        until = len(dataloader)\n",
        "\n",
        "    for i, x in list(enumerate(iter(dataloader)))[:until]:\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Loading batch n°{i}/{len(dataloader)} ...\")\n",
        "        interaction = core.dump_interactions(game, [[x[0], None]], False, variable_length=True)\n",
        "\n",
        "        __messages__.append(interaction.message)\n",
        "\n",
        "    print(\"Successfully generated batches of textual interactions\")\n",
        "\n",
        "    __messages__ = torch.cat(__messages__)[:, :-1]\n",
        "\n",
        "    messages_tokenized = []\n",
        "    messages_char = []\n",
        "\n",
        "    for i in range(__messages__.shape[0]):\n",
        "        messages_tokenized.append(__messages__[i, :].tolist())\n",
        "\n",
        "    if params['vocab_size'] <= 26:\n",
        "        __messages_char_shifted__ = []\n",
        "        make_readable_communication(__messages__, __messages_char_shifted__, __messages__.shape[0], __messages__.shape[1], lower=True)\n",
        "        for i, message in enumerate(__messages_char_shifted__):\n",
        "            messages_char.append(list(message))\n",
        "\n",
        "        res = {\n",
        "            'messages_tokenized': messages_tokenized,\n",
        "            'messages_char': messages_char,\n",
        "        }\n",
        "    else:\n",
        "        print(\"We are sorry, but the vocabulary size is too big to map the arbitrary characeters to natural characters (for further post-processing)\")\n",
        "        res = {\n",
        "            'messages_tokenized': messages_tokenized,\n",
        "        }\n",
        "\n",
        "    for (k, v) in res.items():\n",
        "        print(f\"Successfully saved {k} to a CSV file ...\")\n",
        "        dump_to_csv(data=v, name_data=k)\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGbvUJSfUPSb"
      },
      "outputs": [],
      "source": [
        "# res = generate_interactions(game_rnn, train_loader, name_split='train', noisy=False, ablation=None)\n",
        "# res = generate_interactions(game_rnn, train_loader, name_split='train', noisy=True, ablation=None, until=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc4gYZqeUPL0"
      },
      "outputs": [],
      "source": [
        "# res = generate_interactions(game_rnn, val_loader, name_split='val', noisy=False, ablation=None)\n",
        "# res = generate_interactions(game_rnn, val_loader, name_split='val', noisy=True, ablation=None, until=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDWl8jk4UPFQ"
      },
      "outputs": [],
      "source": [
        "# res = generate_interactions(game_rnn, test_loader, name_split='test', noisy=False, ablation=None)\n",
        "# res = generate_interactions(game_rnn, test_loader, name_split='test', noisy=True, ablation=None, until=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR4NTB_mTeNK"
      },
      "outputs": [],
      "source": [
        "def test2by2(\n",
        "    game, \n",
        "    dataloader, \n",
        "    name_split='train', \n",
        "    noisy=False, \n",
        "    ablation=None,\n",
        "):\n",
        "    global INTERACTIONS_DIR\n",
        "\n",
        "    init_vocab_channel(noisy)\n",
        "\n",
        "    print(f\"Currently generating 2x2 interaction matrices (i.e. testing all possible length-2 messages) for the following split : [{name_split}]\")\n",
        "\n",
        "    if ablation is None:\n",
        "        filename = INTERACTION_DIR + f'{name_split}_split_noisy_{noisy}_2by2'\n",
        "    else:\n",
        "        filename = ablation + f'{name_split}_split_noisy_{noisy}_2by2'\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "    if params['vocab_size'] <= 15:\n",
        "        f, ax = plt.subplots(params['vocab_size'], params['vocab_size'], sharex=True, sharey=True)\n",
        "\n",
        "        for x in range(params['vocab_size']):\n",
        "            for y in range(params['vocab_size']):\n",
        "                    \n",
        "                t = torch.zeros((1, 2)).to(device).long()\n",
        "                t[0, 0] = x\n",
        "                t[0, 1] = y\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    sample = game_rnn.receiver(t)[0].float().cpu()\n",
        "                    sample = sample[0, :].view(28, 28)\n",
        "                    ax[x][y].imshow(sample, cmap='gray')\n",
        "                    \n",
        "                    if y == 0:\n",
        "                        ax[x][y].set_ylabel(f'x={x}')\n",
        "                    if x == 0:\n",
        "                        ax[x][y].set_title(f'y={y}')\n",
        "                    \n",
        "                    ax[x][y].set_yticklabels([])\n",
        "                    ax[x][y].set_xticklabels([])\n",
        "\n",
        "        plt.show()\n",
        "        if ablation is not None:\n",
        "            plt.savefig(filename + '.png')\n",
        "\n",
        "    else:\n",
        "        print(\"We are sorry, but the vocabulary size is too big to perform a matrix study of interactions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7m6ZpZbUThp"
      },
      "outputs": [],
      "source": [
        "# test2by2(game_rnn, train_loader, name_split='train', noisy=False, ablation=None)\n",
        "# test2by2(game_rnn, train_loader, name_split='train', noisy=True, ablation=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LEd5p7DUTbT"
      },
      "outputs": [],
      "source": [
        "# test2by2(game_rnn, val_loader, name_split='val', noisy=False, ablation=None)\n",
        "# test2by2(game_rnn, val_loader, name_split='val', noisy=True, ablation=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZInVVZYUTUj"
      },
      "outputs": [],
      "source": [
        "# test2by2(game_rnn, test_loader, name_split='test', noisy=False, ablation=None)\n",
        "# test2by2(game_rnn, test_loader, name_split='test', noisy=True, ablation=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35IrV8GQtkTs"
      },
      "source": [
        "## F. ⛵ Training the agents ! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V1y2IS9tkk3"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# ---------\n",
        "# ---\n",
        "# -\n",
        "# trainer.train(\n",
        "#     n_epochs=5,\n",
        "# )\n",
        "# core.close()\n",
        "# -\n",
        "# ---\n",
        "# ---------\n",
        "# ---------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBx1cl22cXbs"
      },
      "source": [
        "## G. 🏃 *Optional : running hyperparameter optimization on the game parameters*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u26drtc0L82"
      },
      "source": [
        "#### Note : in order to perform HPO on the communication game studied here, use the NEST module provided along with the EGG framework.\n",
        "*(Since it is cumbersome to use in Jupyter Notebooks, we prefer in the following section to define our own HPO routine in order to allow execution on Google Colab Cloud GPU resources)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfAQrST-cXsL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "%write example.json\n",
        "{\n",
        "  \"vocab_size\": [10, 15],\n",
        "  \"n_epoch\": [15],\n",
        "  \"random_seed\": [0, 1, 2, 3],\n",
        "  \"batch_size\": [256]\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zz8X2inNEX-"
      },
      "source": [
        "## H. 🕸 Ablation study : Running multiple experiments on **vision models**, **datasets** and **reward functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aiBuDiHBCkV"
      },
      "source": [
        "Throughout the ablation study carried out below, we use the following default hyperparameters (in addition to the optimization and architectural hyperparameters whose value by default is defined above) :\n",
        "\n",
        "1. Default *model* : **ResNet-50** (for the *ResNet* family) and  **EfficientNet-B3** (for the *EfficientNet* family)\n",
        "\n",
        "2. Default *dataset* : **CIFAR-100** (for the *natural images* family) and **MNIST** (for the *numbers* family)\n",
        "\n",
        "3. Default *reward function* : **Sequnence length cost**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYxeZhAahxSw"
      },
      "source": [
        "#### *Helper function in order to carry out the ablation on a given parameter*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x27jkvB12CjQ"
      },
      "outputs": [],
      "source": [
        "#@title Decide whether to test ablation on a single batch or to run the full ablation study { run: \"auto\", vertical-output: true, form-width: \"65%\", display-mode: \"code\" }\n",
        "\n",
        "option = \"Full ablation\" #@param [\"Single batch\", \"Full ablation\"]\n",
        "\n",
        "if option == \"Single batch\":\n",
        "    TEST_ONE_BATCH = True\n",
        "    LOG_TO_WANDB = False\n",
        "else:\n",
        "    TEST_ONE_BATCH = False\n",
        "    LOG_TO_WANDB = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs4b9FA7xIaZ"
      },
      "outputs": [],
      "source": [
        "# Use \"raise StopExecution\" in order to interrupt a cell\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "ablation = {}\n",
        "\n",
        "WANDB_EXPERIMENT_GROUP = 'ablation-study'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqfZDR7Lhxlw"
      },
      "outputs": [],
      "source": [
        "def run_ablation_study(params, parameter='model_name', model=None, add_name=None, **kwargs):\n",
        "    # We copy the default hyperparameters\n",
        "    params = copy.deepcopy(params)\n",
        "    params.update(kwargs)\n",
        "\n",
        "    values = ablation[parameter]\n",
        "\n",
        "    print(f\"\\nPerforming an ablation study on the following parameter : [{parameter}]\\n\")\n",
        "    print(f\"The following experiments will be carried out :\")\n",
        "    for (i, v) in enumerate(values):\n",
        "        print(f\"- [{i + 1}/{len(values)}] {parameter}='{v}'\")\n",
        "\n",
        "    def single_run(parameter, value, dataset):\n",
        "        global NUM_CHANNELS, VOCAB, CHANNEL, INTERACTIONS_DIR\n",
        "\n",
        "        print(params)\n",
        "\n",
        "        NUM_CHANNELS = n_channels[params['dataset']]\n",
        "\n",
        "        value = params[parameter]\n",
        "        model_name = params['model_name']\n",
        "        dataset = params['dataset']\n",
        "\n",
        "        \"\"\"\n",
        "        if not (parameter in ['model_name', 'dataset']):\n",
        "            if add_name is None:\n",
        "                NAME_RUN = f'Ablation study : P[{parameter}], V[{value}], M[{model_name}], D[{dataset}]'\n",
        "                NAME_CHECKPOINT = f'param={parameter}_value={value}_model={model_name}_dataset={dataset}'\n",
        "            else:\n",
        "                NAME_RUN = f'Ablation study : P[{parameter}], V[{value}], M[{model_name}], D[{dataset}], A[{add_name}]'\n",
        "                NAME_CHECKPOINT = f'param={parameter}_value={value}_model={model_name}_dataset={dataset}_cond={add_name}'\n",
        "        else:\n",
        "            if add_name is None:\n",
        "                NAME_RUN = f'Ablation study : M[{model_name}], D[{dataset}]'\n",
        "                NAME_CHECKPOINT = f'model={model_name}_dataset={dataset}'\n",
        "            else:\n",
        "                NAME_RUN = f'Ablation study : M[{model_name}], D[{dataset}], A[{add_name}]'\n",
        "                NAME_CHECKPOINT = f'model={model_name}_dataset={dataset}_cond={add_name}'\n",
        "        \"\"\"\n",
        "\n",
        "        if not (parameter in ['model_name', 'dataset']):\n",
        "            if add_name is None:\n",
        "                NAME_RUN = f'Ablation study : P[{parameter}], V[{value}]'\n",
        "                NAME_CHECKPOINT = f'param={parameter}_value={value}'\n",
        "            else:\n",
        "                NAME_RUN = f'Ablation study : P[{parameter}], V[{value}], A[{add_name}]'\n",
        "                NAME_CHECKPOINT = f'param={parameter}_value={value}_cond={add_name}'\n",
        "\n",
        "        SUB_DIRECTORY = WANDB_EXPERIMENT_GROUP + '/'\n",
        "        DIR_CHECKPOINT = CHECKPOINTS_DIR + SUB_DIRECTORY + NAME_CHECKPOINT + '/'\n",
        "        WANDB_EXPERIMENT_NAME = NAME_RUN\n",
        "\n",
        "        print(f\"NAME_RUN={NAME_RUN}\")\n",
        "        print(f\"NAME_CHECKPOINT={NAME_CHECKPOINT}\")\n",
        "        print(f\"DIR_CHECKPOINT={DIR_CHECKPOINT}\")\n",
        "\n",
        "        # -------------------------------------------------------- #\n",
        "        # 1. Instantiating the Model using the finetuned version. #\n",
        "        # ------------------------------------------------------ #\n",
        "        \"\"\"\n",
        "        model, dim_vision_out = retrieve_finetuned_vision_model(\n",
        "            params['model_name'], \n",
        "            params['dataset'], \n",
        "            add_name=add_name)\n",
        "        \n",
        "        model = model.to(device) # Moving the dataset to the GPU, if it is available\n",
        "        \"\"\"\n",
        "\n",
        "        # ------------------------------- #\n",
        "        # 2. Instantiating the Datasets. #\n",
        "        # ----------------------------- #\n",
        "        # a. Creating the appropriatge data augmentation scheme (image-level transform operators)\n",
        "        multi_channel = not params['dataset'] in ['mnist', 'k-mnist', 'q-mnist', 'fashion-mnist']\n",
        "        transform_train = TransformsAugment(size=sizes[params['dataset']], multi_channel=multi_channel)\n",
        "        transform_val_test = TransformsAugment(size=sizes[params['dataset']], multi_channel=multi_channel)\n",
        "\n",
        "        # b. Loading the right dataset split\n",
        "        \"\"\"\n",
        "        split = image_datasets[params['dataset']](\n",
        "            transform_train, \n",
        "            transform_val_test,\n",
        "        )\n",
        "        train_loader, val_loader, test_loader = split.values()\n",
        "        \"\"\"\n",
        "\n",
        "        # ----------------------------- #\n",
        "        # 3. Instantiating the Agents. #\n",
        "        # --------------------------- #\n",
        "        # Sender / receiver models responsible respectively for producing / processing the initial / final RNN hidden state\n",
        "        sender = Sender(\n",
        "            vision, \n",
        "            input_size=dim_vision_out, \n",
        "            output_size=params['s_hidden_size'], \n",
        "            hidden_sizes=params['s_hidden_sizes'],\n",
        "        )\n",
        "        receiver = Receiver(\n",
        "            input_size=params['r_hidden_size'],\n",
        "            output_size=int(sizes[params['dataset']] ** 2),\n",
        "            hidden_sizes=params['s_hidden_sizes'],\n",
        "        )\n",
        "\n",
        "        # Wrapping the sender / receiver models into a RNN module in order to handle variable-length messages\n",
        "        sender_rnn = core.RnnSenderReinforce(\n",
        "            agent=sender, \n",
        "            vocab_size=params['vocab_size'], \n",
        "            embed_dim=params['s_emb_size'], \n",
        "            hidden_size=params['s_hidden_size'], \n",
        "            cell=params['s_cell'], \n",
        "            max_len=params['max_len'], \n",
        "            num_layers=params['s_num_layers'],\n",
        "        )\n",
        "        receiver_rnn = core.RnnReceiverDeterministic(\n",
        "            agent=receiver, \n",
        "            vocab_size=params['vocab_size'], \n",
        "            embed_dim=params['r_emb_size'], \n",
        "            hidden_size=params['r_hidden_size'], \n",
        "            cell=params['r_cell'], \n",
        "            num_layers=params['r_num_layers'],\n",
        "        )\n",
        "\n",
        "        # --------------------------------- #\n",
        "        # 4. Instantiating the Vocabulary. #\n",
        "        # ------------------------------- #\n",
        "        VOCAB = Vocabulary(\n",
        "            vocab_model=params['vocab_model'],\n",
        "            vocab_size=params['vocab_size'],\n",
        "            vocab_loss_c=params['vocab_loss_c'],\n",
        "            vocab_loss_mute=params['vocab_loss_mute'],\n",
        "            vocab_mu_dist=params['vocab_mu_dist'],\n",
        "            vocab_temperature=params['vocab_temperature'],\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # -------------------------------------------------- #\n",
        "        # 5. Instantiating the Noisy Communication Channel. #\n",
        "        # ------------------------------------------------ #\n",
        "        CHANNEL = Channel(\n",
        "            max_len=params['max_len'],\n",
        "            channel_top_k=params['channel_top_k'],\n",
        "            channel_temperature=params['channel_temperature'],\n",
        "            vocabulary=VOCAB,\n",
        "            p_random_insertion=params['p_random_insertion'],\n",
        "            p_random_deletion=params['p_random_deletion'],\n",
        "            p_random_permutation=params['p_random_permutation'],\n",
        "            p_random_corruption=params['p_random_corruption'],\n",
        "            corruption_function=params['corruption_function'],   \n",
        "        )\n",
        "\n",
        "        # --------------------------------------- #\n",
        "        # 6. Instantiating the Game Environment. #\n",
        "        # ------------------------------------- #\n",
        "        game_rnn = SenderReceiverRnnReinforce(\n",
        "            sender_rnn, \n",
        "            receiver_rnn, \n",
        "            loss=params['task_loss'][1], \n",
        "            sender_entropy_coeff=params['s_entropy_coeff'], \n",
        "            receiver_entropy_coeff=params['r_entropy_coeff'],\n",
        "        )\n",
        "\n",
        "        # ----------------------------- #\n",
        "        # 7. Instantiating a WandB run #\n",
        "        # --------------------------- #\n",
        "        WANDB_RUN = wandb.init(\n",
        "            project=WANDB_PROJECT, \n",
        "            entity=WANDB_ENTITY,\n",
        "            notes=WANDB_NOTES,\n",
        "            name=WANDB_EXPERIMENT_NAME,\n",
        "            group=WANDB_EXPERIMENT_GROUP,\n",
        "            save_code=True,\n",
        "        )\n",
        "        WANDB_RUN_ID = WANDB_RUN.id\n",
        "\n",
        "        # -------------------------------- #\n",
        "        # 7. Instantiating the Callbacks. #\n",
        "        # ------------------------------ #\n",
        "        checkpoint_saver_callback = core.CheckpointSaver(\n",
        "            checkpoint_path=DIR_CHECKPOINT,\n",
        "            checkpoint_freq=params['checkpoint_freq'],\n",
        "            prefix=NAME_CHECKPOINT,\n",
        "            max_checkpoints=params['max_checkpoints'],\n",
        "        )\n",
        "        interaction_saver_callback = core.InteractionSaver(\n",
        "            train_epochs=list(range(1, params['num_epochs'] + 1, 2)),\n",
        "            test_epochs=list(range(2, params['num_epochs'] + 1, 2)),\n",
        "            checkpoint_dir=INTERACTION_DIR,\n",
        "        )\n",
        "        callbacks=[\n",
        "           # early_stopping_callback, # Optimization-related callbakcs\n",
        "           \n",
        "           checkpoint_saver_callback, # Checkpointing callbacks\n",
        "           interaction_saver_callback,\n",
        "           \n",
        "           wandb_logger, # ML experiment logging and management callbacks\n",
        "           console_logger_callback,\n",
        "           progress_bar_callback,\n",
        "\n",
        "           # disentanglement_metric_callback, # Linguistic analysis of the interactions\n",
        "           message_entropy_metric_callback,\n",
        "        ]\n",
        "          \n",
        "        # callbacks += topographic_similarity_metric_callbacks\n",
        "\n",
        "        # -------------------------------- #\n",
        "        # 8. Instantiating the Optimizer. #\n",
        "        # ------------------------------ #\n",
        "        optimizer = torch.optim.Adam([\n",
        "            {'params': game_rnn.sender.parameters(), # Sender-side optimization hyperparameters\n",
        "             'lr': params['s_lr'],\n",
        "            },\n",
        "            {'params': game_rnn.receiver.parameters(), # Receiver-side optimization hyperparameters\n",
        "             'lr': params['r_lr'],\n",
        "            },\n",
        "        ])\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer=optimizer, \n",
        "            T_0=1, \n",
        "            T_mult=params['s_lr_scheduler_mult'], \n",
        "            eta_min=params['s_lr_scheduler_eta_min'], \n",
        "            last_epoch=-1,\n",
        "        ),\n",
        "\n",
        "        # ------------------------------ #\n",
        "        # 9. Instantiating the Trainer. #\n",
        "        # ---------------------------- #\n",
        "        trainer = core.Trainer(\n",
        "            game=game_rnn, \n",
        "            optimizer=optimizer, # optimizer \n",
        "            train_data=train_loader, \n",
        "            validation_data=val_loader,\n",
        "            # grad_norm=params['grad_norm'],\n",
        "            device=device,\n",
        "            callbacks=callbacks,\n",
        "        )\n",
        "\n",
        "        # ----------------------------------------------------- #\n",
        "        # 10. Instantiating the Predictions logging functions. #\n",
        "        # --------------------------------------------------- #\n",
        "\n",
        "        # --------------------------- #\n",
        "        # 11. Training the agents !. #\n",
        "        # ------------------------- #\n",
        "        trainer.train(\n",
        "            n_epochs=params['num_epochs'],\n",
        "        )\n",
        "        core.close()\n",
        "\n",
        "        # ---------------------------------------------- #\n",
        "        # 12. Post-hoc linguistic analysis subroutines. #\n",
        "        # -------------------------------------------- #\n",
        "\n",
        "        ablation = INTERACTIONS_DIR + 'ablation-study' + '/' + WANDB_EXPERIMENT_NAME + '/'\n",
        "\n",
        "        print(ablation)\n",
        "\n",
        "\n",
        "\n",
        "        # A. Evaluating the final performance of the communicating agents on the training set\n",
        "        init_vocab_channel(noisy=True)\n",
        "        train_loss_noisy, _ = trainer.eval(data=train_loader)\n",
        "        print(f\"Train loss noisy : {train_loss_noisy}\")\n",
        "        init_vocab_channel(noisy=False)\n",
        "        train_loss_clean, _ = trainer.eval(data=train_loader)\n",
        "        print(f\"Train loss clean : {train_loss_clean}\")\n",
        "\n",
        "        wandb.log({\n",
        "            'train_loss_noisy': train_loss_noisy,\n",
        "            'train_loss_clean': train_loss_clean,\n",
        "        })\n",
        "\n",
        "        plot(game_rnn, train_loader, name_split='train', noisy=False, ablation=ablation)\n",
        "        plot(game_rnn, train_loader, name_split='train', noisy=True, ablation=ablation)  \n",
        "\n",
        "        res = generate_interactions(game_rnn, train_loader, name_split='train', noisy=False, ablation=ablation)\n",
        "        res = generate_interactions(game_rnn, train_loader, name_split='train', noisy=True, ablation=ablation, until=200)  \n",
        "\n",
        "        test2by2(game_rnn, train_loader, name_split='train', noisy=False, ablation=ablation)\n",
        "        test2by2(game_rnn, train_loader, name_split='train', noisy=True, ablation=ablation)\n",
        "\n",
        "\n",
        "\n",
        "        # B. Evaluating the final performance of the communicating agents on the validation set\n",
        "        init_vocab_channel(noisy=True)\n",
        "        val_loss_noisy, _ = trainer.eval(data=val_loader)\n",
        "        print(f\"Validation loss noisy : {val_loss_noisy}\")\n",
        "        init_vocab_channel(noisy=False)\n",
        "        val_loss_clean, _ = trainer.eval(data=val_loader)\n",
        "        print(f\"Validation loss clean : {val_loss_clean}\")\n",
        "\n",
        "        wandb.log({\n",
        "            'val_loss_noisy': val_loss_noisy,\n",
        "            'val_loss_clean': val_loss_clean,\n",
        "        })\n",
        "\n",
        "        plot(game_rnn, val_loader, name_split='val', noisy=False, ablation=ablation)\n",
        "        plot(game_rnn, val_loader, name_split='val', noisy=True, ablation=ablation) \n",
        "\n",
        "        res = generate_interactions(game_rnn, val_loader, name_split='val', noisy=False, ablation=ablation)\n",
        "        res = generate_interactions(game_rnn, val_loader, name_split='val', noisy=True, ablation=ablation, until=200)\n",
        "\n",
        "        test2by2(game_rnn, val_loader, name_split='val', noisy=False, ablation=ablation)\n",
        "        test2by2(game_rnn, val_loader, name_split='val', noisy=True, ablation=ablation)\n",
        "\n",
        "\n",
        "\n",
        "        # C. Evaluating the final performance of the communicating agents on the test set\n",
        "        init_vocab_channel(noisy=True)\n",
        "        test_loss_noisy, _ = trainer.eval(data=test_loader)\n",
        "        print(f\"Test loss noisy : {test_loss_noisy}\")\n",
        "        init_vocab_channel(noisy=False)\n",
        "        test_loss_clean, _ = trainer.eval(data=test_loader)\n",
        "        print(f\"Test loss clean : {test_loss_clean}\")\n",
        "\n",
        "        wandb.log({\n",
        "            'test_loss_noisy': test_loss_noisy,\n",
        "            'test_loss_clean': test_loss_clean,\n",
        "        })\n",
        "\n",
        "        plot(game_rnn, test_loader, name_split='test', noisy=False, ablation=ablation)\n",
        "        plot(game_rnn, test_loader, name_split='test', noisy=True, ablation=ablation)\n",
        "\n",
        "        res = generate_interactions(game_rnn, test_loader, name_split='test', noisy=False, ablation=ablation)\n",
        "        res = generate_interactions(game_rnn, test_loader, name_split='test', noisy=True, ablation=ablation, until=200)\n",
        "\n",
        "        test2by2(game_rnn, test_loader, name_split='test', noisy=False, ablation=ablation)\n",
        "        test2by2(game_rnn, test_loader, name_split='test', noisy=True, ablation=ablation)\n",
        "\n",
        "    for (i, v) in enumerate(values):\n",
        "        print('\\n\\n# ' + '-' * 70 + ' #')\n",
        "        print(f\"  Running ablation experiment [{i + 1}/{len(values)}]  : {parameter}='{v}'\")\n",
        "        print('# ' + '-' * 70 + ' #')\n",
        "\n",
        "        params[parameter] = v\n",
        "\n",
        "        t_start = time.time()\n",
        "        single_run(parameter=parameter, value=v, dataset='mnist')\n",
        "        t_end = time.time()\n",
        "        print(f\"Time elapsed : {(t_end - t_start):.2f}s !\\n\\n\") \n",
        "\n",
        "\n",
        "params['num_epochs'] = 1\n",
        "s_hidden_sizes = [\n",
        "                [400],\n",
        "                [400, 500],\n",
        "                [400, 600, 500],\n",
        "                [400, 600, 800, 500],\n",
        "                [400, 800],\n",
        "]\n",
        "ablation['s_hidden_sizes'] = s_hidden_sizes\n",
        "run_ablation_study(params, parameter='s_hidden_sizes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ51lkgnZIcb"
      },
      "outputs": [],
      "source": [
        "!ls \"drive/My Drive/Projects/nlp_emergent_languages/interactions/ablation-study/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql6S2MvRAqqK"
      },
      "outputs": [],
      "source": [
        "# INTERACTIONS_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhCuCBA3As5E"
      },
      "outputs": [],
      "source": [
        "# !ls \"drive/My Drive/Projects/nlp_emergent_languages/interactions/ablation-study/Ablation study : P[s_hidden_sizes], V[[400]]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGsvsOO8NYRA"
      },
      "source": [
        "#### **Vision models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R9wwvsA5A3p"
      },
      "source": [
        "💿 `param = model_name`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPYNlHDzNEqE"
      },
      "outputs": [],
      "source": [
        "ablation['model_name'] = list(resnets.keys()) + list(efficientnets.keys())\n",
        "\n",
        "run_ablation_study(params, parameter='model_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPfJRnhaNehh"
      },
      "source": [
        "#### **Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f6lry_nqN7s"
      },
      "source": [
        "💿 `param = dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOd9zmb0Ne1D"
      },
      "outputs": [],
      "source": [
        "ablation['dataset'] = image_datasets.keys()\n",
        "\n",
        "run_ablation_study(params, parameter='dataset', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8Ds3t8npEXN"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='dataset', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDrChy9805dJ"
      },
      "source": [
        "#### **Random seed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkurPF3xqMPn"
      },
      "source": [
        "💿 `param = random_seed`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxBT8MNl05sh"
      },
      "outputs": [],
      "source": [
        "get_seed = lambda s: random.seed(a=s)\n",
        "\n",
        "ablation['random_seed'] = map(get_seed, [\n",
        "                                         'emergent',\n",
        "                                         'languages',\n",
        "                                         'are',\n",
        "                                         'very',\n",
        "                                         'cool',\n",
        "                                         ',',\n",
        "                                         'yes',\n",
        "                                         'indeed',\n",
        "                                         '!'\n",
        "])\n",
        "\n",
        "run_ablation_study(params, parameter='random_seed', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi5A9ONspE52"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='random_seed', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTMZQ-SO1Lej"
      },
      "source": [
        "#### *Stochastic grid search* : **Sender** & **Receiver**-level architectural parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZfh_ROM1LtI"
      },
      "outputs": [],
      "source": [
        "s_hidden_sizes = [\n",
        "                [400],\n",
        "                [400, 500],\n",
        "                [400, 600, 500],\n",
        "                [400, 600, 800, 500],\n",
        "                [400, 800],\n",
        "]\n",
        "r_hidden_sizes = s_hidden_sizes\n",
        "\n",
        "s_hidden_size = [10, 20, 40, 80]\n",
        "r_hidden_size = s_hidden_size\n",
        "\n",
        "s_emb_size = [5, 10, 20, 40]\n",
        "r_emb_size = s_emb_size\n",
        "\n",
        "s_cell = ['lstm', 'rnn', 'gru']\n",
        "r_cell = s_cell\n",
        "\n",
        "s_num_layers = [1, 2, 3]\n",
        "r_num_layers = s_num_layers\n",
        "\n",
        "ablation['s_hidden_sizes'] = s_hidden_sizes\n",
        "ablation['r_hidden_sizes'] = r_hidden_sizes\n",
        "ablation['s_hidden_size'] = s_hidden_size\n",
        "ablation['r_hidden_size'] = r_hidden_size\n",
        "ablation['s_emb_size'] = s_emb_size\n",
        "ablation['r_emb_size'] = r_emb_size\n",
        "ablation['s_cell'] = s_cell\n",
        "ablation['r_cell'] = r_cell\n",
        "ablation['s_num_layers'] = s_num_layers\n",
        "ablation['r_num_layers'] = r_num_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDVFGFZypikn"
      },
      "source": [
        "💿 `param = hidden_sizes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55SeoL7xiWLw"
      },
      "outputs": [],
      "source": [
        "params['n_epochs'] = 10\n",
        "run_ablation_study(params, parameter='s_hidden_sizes', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzyavXq6_MVH"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_hidden_sizes', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTwt7DFapAi8"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_hidden_sizes', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmNSHyjR_Qfx"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_hidden_sizes', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8PJHKsHp2gb"
      },
      "source": [
        "💿 `param = hidden_size`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPGlk8hlia9y"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_hidden_size', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBqm9K7v_S-I"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_hidden_size', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxc4KVcwo_US"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_hidden_size', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8a6CD5B_TUH"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_hidden_size', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET53IgWRp29E"
      },
      "source": [
        "💿 `param = emb_size`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65Qk-1Xaia2e"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_emb_size', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojmAYKQO_q2F"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_emb_size', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StAbbjDRo-LG"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_emb_size', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWnF9jIS_rLs"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_emb_size', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkpIoTqnp3kZ"
      },
      "source": [
        "💿 `param = cell`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYJAv37Ric-a"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_cell', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3jANmgi_reQ"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_cell', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRp8lfcwo9Kz"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_cell', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHIgXzuX_r21"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_cell', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5CJVCmwp35P"
      },
      "source": [
        "💿 `param = num_layers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHcu-h8Vidr-"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_num_layers', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xutwI-gU_saw"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_num_layers', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAkhSsO_o7g0"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_num_layers', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbWzQCKS_stq"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_num_layers', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guo9-iun6338"
      },
      "outputs": [],
      "source": [
        "# Sender-specific parameters\n",
        "s_entropy_coeff = [0., 0.0015, 0.015, 0.15]\n",
        "s_lr = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2]\n",
        "ablation['s_entropy_coeff'] = s_entropy_coeff\n",
        "ablation['s_lr'] = s_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHx2zIdv64c9"
      },
      "outputs": [],
      "source": [
        "# Receiver-specific parameters\n",
        "r_entropy_coeff = [0., 0.0015, 0.015, 0.15]\n",
        "s_lr = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1]\n",
        "ablation['r_entropy_coeff'] = r_entropy_coeff\n",
        "ablation['r_lr'] = r_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mafDDEuSp_Uy"
      },
      "source": [
        "💿 `param = s_lr`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5VVgMawiMGd"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_lr', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrMOIF1XozU0"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_lr', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKu76dssqBTV"
      },
      "source": [
        "💿 `param = r_lr`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3kK5M-6iQ7z"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_lr', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE6PjOCOozC1"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_lr', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O58__YH2qDJE"
      },
      "source": [
        "💿 `param = s_entropy_coeff`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR8xwr1YiSBF"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_entropy_coeff', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrk1r4Tpoyzf"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='s_entropy_coeff', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfzSkANOqE5W"
      },
      "source": [
        "💿 `param = r_entropy_coeff`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hR2N_HViSXf"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_entropy_coeff', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMGN8G84oyZt"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='r_entropy_coeff', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYHXjLbqNfGf"
      },
      "source": [
        "#### **Reward functions** (*i.e.* communication channel **stochasticity levels** & token-level **similarity mappings**)\n",
        "\n",
        "Here, we investigate the extent to which a specific ordering of corruption functions applied to our communication channel's transfer function impact the learning performance of our agents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmFwnhr5qJhE"
      },
      "source": [
        "💿 `param = corruption_function`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe1VU4DeNfZP"
      },
      "outputs": [],
      "source": [
        "params['p_random_insertion'] = 0.05\n",
        "params['p_random_deletion'] = 0.05\n",
        "params['p_random_permutation'] = 0.05\n",
        "params['p_random_coruption'] = 0.05\n",
        "ablation['corruption_function'] = [\n",
        "    ['corruption', 'permutation', 'deletion', 'insertion'],\n",
        "    ['corruption', 'permutation', 'deletion'],\n",
        "    ['corruption', 'permutation'],\n",
        "    ['insertion', 'deletion', 'permutation', 'corruption'],\n",
        "    ['insertion', 'deletion', 'permutation'],\n",
        "    ['insertion', 'deletion'],\n",
        "    ['insertion'],\n",
        "    ['deletion'],\n",
        "    ['permutation'],\n",
        "    []\n",
        "]\n",
        "\n",
        "run_ablation_study(params, parameter='corruption_function', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlpyWXu1owxB"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='corruption_function', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn6x-fj4AQaU"
      },
      "source": [
        "#### **Vocabulary**-level parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "homQKkEFqQUk"
      },
      "source": [
        "💿 `param = vocab_size`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM9MgUpGAQsT"
      },
      "outputs": [],
      "source": [
        "ablation['vocab_size'] = [5, 10, 20, 40, 80, 160, 320, 640, 1_280, 2_560, 5_120, 10_240, 20_480, 40_960]\n",
        "\n",
        "run_ablation_study(params, parameter='vocab_size', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH3LsR0DoioS"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='vocab_size', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqCjzAPpqQ3w"
      },
      "source": [
        "💿 `param = vocab_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Ujm4nujErU"
      },
      "outputs": [],
      "source": [
        "ablation['vocab_model'] = ['uniform',\n",
        "                           '1d',\n",
        "                           'chromatic',\n",
        "                           '2d',\n",
        "                           'phoneme_accurate',\n",
        "                           'keyboard_accurate',\n",
        "                           'tree_hierarchical']\n",
        "\n",
        "run_ablation_study(params, parameter='vocab_model', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urdzqSBRojC1"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='vocab_model', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYWHELaDqRz4"
      },
      "source": [
        "💿 `param = loss_c`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBNsizbIjJ81"
      },
      "outputs": [],
      "source": [
        "ablation['loss_c'] = [1]\n",
        "\n",
        "run_ablation_study(params, parameter='loss_c', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9Mx7mHOojXs"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='loss_c', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8Z5OrLpqS4X"
      },
      "source": [
        "💿 `param = loss_mute`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy-58Zs9jJ1j"
      },
      "outputs": [],
      "source": [
        "ablation['loss_mute'] = [1]\n",
        "\n",
        "run_ablation_study(params, parameter='loss_mute', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Wkaa4t8oj9v"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='loss_mute', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrrca18pqTlc"
      },
      "source": [
        "💿 `param = mu_dist`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLVurqhrjJqk"
      },
      "outputs": [],
      "source": [
        "ablation['mu_dist'] = [1]\n",
        "\n",
        "run_ablation_study(params, parameter='mu_dist', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa09KAdjokOp"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='mu_dist', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J5yRqndqT8m"
      },
      "source": [
        "💿 `param = vocab_temperature`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XVIiTM_jJNr"
      },
      "outputs": [],
      "source": [
        "ablation['vocab_temperature'] = [0.1, 0.2, 0.5, 1, 2, 3, 5]\n",
        "\n",
        "run_ablation_study(params, parameter='vocab_temperature', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfXh-lP0oh2j"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='vocab_temperature', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7qEaWGBARFU"
      },
      "source": [
        "#### **Channel**-level parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3bzz_EUqf_u"
      },
      "source": [
        "💿 `param = max_len`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwXVV5uRARU8"
      },
      "outputs": [],
      "source": [
        "ablation['max_len'] = [1, 2, 3, 4, 5, 7, 9, 12, 15, 20, 30, 50, 100]\n",
        "\n",
        "run_ablation_study(params, parameter='max_len', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "netPMZIfoUhK"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='max_len', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmGXW7xsqgWp"
      },
      "source": [
        "💿 `param = top_k`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-nvn6DzjUFi"
      },
      "outputs": [],
      "source": [
        "ablation['top_k'] = [3, 5, 10, 15, 20]\n",
        "\n",
        "run_ablation_study(params, parameter='top_k', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYxdazwVoUQO"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='top_k', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VAJx7Ikqgzl"
      },
      "source": [
        "💿 `param = channel_temperature`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6UCYZvvjdHa"
      },
      "outputs": [],
      "source": [
        "ablation['channel_temperature'] = [0.1, 0.2, 0.5, 1, 2, 3, 5]\n",
        "\n",
        "run_ablation_study(params, parameter='channel_temperature', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ6kleFeoT-C"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='channel_temperature', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drusB_hCqhJp"
      },
      "source": [
        "💿 `param = p_random_insertion`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OUKQGgrjckB"
      },
      "outputs": [],
      "source": [
        "params['num_epohs'] = 1\n",
        "\n",
        "params['p_random_insertion'] = 0.05\n",
        "params['p_random_deletion'] = 0.05\n",
        "params['p_random_permutation'] = 0.05\n",
        "params['p_random_coruption'] = 0.05\n",
        "\n",
        "ablation['p_random_insertion'] = [0, 0.001, 0.002, 0.006, 0.01, 0.02, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "\n",
        "run_ablation_study(params, parameter='p_random_insertion', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOvyUb9QoTre"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='p_random_insertion', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysiUUZkaqh_l"
      },
      "source": [
        "💿 `param = p_random_deletion`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltj1-AyhjcbZ"
      },
      "outputs": [],
      "source": [
        "params['num_epohs'] = 1\n",
        "\n",
        "params['p_random_insertion'] = 0.05\n",
        "params['p_random_deletion'] = 0.05\n",
        "params['p_random_permutation'] = 0.05\n",
        "params['p_random_coruption'] = 0.05\n",
        "\n",
        "ablation['p_random_deletion'] = [0, 0.001, 0.002, 0.006, 0.01, 0.02, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "\n",
        "run_ablation_study(params, parameter='p_random_deletion', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ellWyFKBoTKr"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='p_random_deletion', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9x4pgxTqiWh"
      },
      "source": [
        "💿 `param = p_random_permutation`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fSNzzM1jcUX"
      },
      "outputs": [],
      "source": [
        "params['num_epohs'] = 1\n",
        "\n",
        "params['p_random_insertion'] = 0.05\n",
        "params['p_random_deletion'] = 0.05\n",
        "params['p_random_permutation'] = 0.05\n",
        "params['p_random_coruption'] = 0.05\n",
        "\n",
        "ablation['p_random_permutation'] = [0, 0.001, 0.002, 0.006, 0.01, 0.02, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4] # \n",
        "\n",
        "run_ablation_study(params, parameter='p_random_permutation', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb_wDGgUoSr-"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='p_random_permutation', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye33NNfqqixV"
      },
      "source": [
        "💿 `param = p_random_corruption`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1OzPxUgjcMS"
      },
      "outputs": [],
      "source": [
        "params['num_epohs'] = 1\n",
        "\n",
        "params['p_random_insertion'] = 0.05\n",
        "params['p_random_deletion'] = 0.05\n",
        "params['p_random_permutation'] = 0.05\n",
        "params['p_random_coruption'] = 0.05\n",
        "\n",
        "ablation['p_random_corruption'] = [0, 0.001, 0.002, 0.006, 0.01, 0.02, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4] # \n",
        "\n",
        "run_ablation_study(params, parameter='p_random_corruption', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrARE3M7oSNg"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='p_random_corruption', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RtTdIpYARhc"
      },
      "source": [
        "#### **Optimization**-level parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFKf1o7sqjjW"
      },
      "source": [
        "💿 `param = grad_norm`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQD7bGUVAR30"
      },
      "outputs": [],
      "source": [
        "ablation['grad_norm'] = [0.1, 0.5, 1, 2, 4]\n",
        "\n",
        "run_ablation_study(params, parameter='grad_norm', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWcANZEHoQRQ"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='grad_norm', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2O7uOWhtyK8"
      },
      "source": [
        "#### **Task**-level parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl3tBzcaqkBB"
      },
      "source": [
        "💿 `param = task_loss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZMGZzyatycb"
      },
      "outputs": [],
      "source": [
        "ablation['task_loss'] = [\n",
        "                         ('reconstruction', loss_bce_reconstruction, 'bce'),\n",
        "                         ('discrimination', loss_nll_discrimination, 'nll'),\n",
        "                         ('discrimination', loss_accuracy_discrimination, 'accuracy'),\n",
        "]\n",
        "\n",
        "run_ablation_study(params, parameter='task_loss', model='resnet-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9AAlTxboNY7"
      },
      "outputs": [],
      "source": [
        "run_ablation_study(params, parameter='task_loss', model='efficientnet-b3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmvLZ9dL5vzP"
      },
      "source": [
        "## I. 🚪 Closing the experiment and freeing the models loaded in the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ6ffBJg5uUd"
      },
      "outputs": [],
      "source": [
        "# - ⚠️ - # - ⚠️ - # - ⚠️ -\n",
        "# Important in order to prevent the 'WandB backend process has shutdown error' !\n",
        "wandb.finish()\n",
        "# - ⚠️ - # - ⚠️ - # - ⚠️ -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPxZ2S8PxVUd"
      },
      "source": [
        "---\n",
        "# 5. 🔍 **Evaluating** and investigating the induced language 🔎\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIUn11Ck6Wec"
      },
      "source": [
        "### A. 🤙🏼 Helper function to visualize interactions for any input model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbW4IJMyxc_f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU1SEUzp0J8Z"
      },
      "source": [
        "---\n",
        "# 6. 🚧 To-do list and future work 🚧\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   Resolve the issue with **FakeData** exceeding GPU memory\n",
        "2.   Resolve the issue with the shape mismatch on **Caltech-101 and -256**\n",
        "3.   Download **Places365**, **iNaturalist** and **ImageNet** on dedicated a Google GCP engine\n",
        "4.   Optimize the finetuning pipeline on \"Finetuning Vision Models\" : LR Scheduler, higher batch size, etc ... to improve classification performance\n",
        "5.   Resolve the F1_score=NaN problem"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Noisy Channel Communication - Emergent Languages",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}