{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmapOH-mv0QJ"
      },
      "source": [
        "**Notebook permanent link** : \n",
        "If you wish to access this notebook in the future, please ue this link : https://colab.research.google.com/drive/12m-SOfFKWQzys5h-z6p8caJ8-6Esgu1e?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW2sGfKxzYr4"
      },
      "source": [
        "*Note* : Run the following code in order to prevent you from being connected from Google Colab's VM :\n",
        "```\n",
        "function KeepClicking(){\n",
        "console.log(\"Clicking\");\n",
        "document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(KeepClicking,60000)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zalo1wduwwQ"
      },
      "source": [
        "## 🧱 A. Installing useful dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1rMOrWpvg41"
      },
      "outputs": [],
      "source": [
        "# EGG : Emergence of lanGuage in Games environment (see https://github.com/facebookresearch/EGG for more information)\n",
        "!pip install --quiet git+https://github.com/facebookresearch/EGG.git\n",
        "!pip install --quiet torchvision\n",
        "!pip install --quiet wandb\n",
        "!pip install --quiet pytorch_lightning\n",
        "!pip install --quiet h5py\n",
        "!pip install --quiet pytorch-ignite\n",
        "!pip install --quiet tensorboardX\n",
        "!pip install --quiet opendatasets\n",
        "!pip install --quiet efficientnet-pytorch\n",
        "!pip install --quiet timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFDxiRdukeS"
      },
      "source": [
        "## 🛣 B. Defining useful hyperparameters used throughout the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8quaEJMmsDD"
      },
      "outputs": [],
      "source": [
        "# Please adapt the directories below to your own file arborescence\n",
        "# Due to storage limits imposed by Torchvision, you should download ImageNet, Tiny-Imagenet, Places365 and \n",
        "# iNaturalist independently\n",
        "PROJECT_DIR = \"drive/My Drive/Projects/nlp_emergent_languages/\"\n",
        "CHECKPOINTS_DIR = PROJECT_DIR + 'checkpoints/'\n",
        "INTERACTIONS_DIR = PROJECT_DIR + 'interactions/'\n",
        "DATASETS_DIR = PROJECT_DIR + 'datasets/'\n",
        "PRETRAINED_MODELS_DIR = '/content/' + PROJECT_DIR + 'pretrained_models/'\n",
        "FINETUNED_MODELS_DIR = '/content/' + PROJECT_DIR + 'finetuned_models/'\n",
        "\n",
        "DATASET_IMAGENET_DIR = 'imagenet/imagenet/'\n",
        "DATASET_TINY_IMAGENET_DIR = 'tiny-imagenet/tiny-imagenet-200/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zjmRfbYn0ld"
      },
      "outputs": [],
      "source": [
        "WANDB_API_KEY = \"ENTER_YOUR_OWN_API_KEY_HERE\"\n",
        "WANDB_PROJECT = \"ENTER_YOUR_OWN_WANDB_PROJECT_HERE\"\n",
        "WANDB_ENTITY = \"ENTER_YOUR_OWN_WANDB_PROJECT_GROUP_HERE\"\n",
        "WANDB_NOTES = \"We assess the robustness and generalization / compositionality capabilities of emergent languages \\\n",
        "in a two-agent signaling game under channel noisyness constriants\"\n",
        "WANDB_EXPERIMENT_GROUP=\"vision-model-pretraining\"  # 'reconstruction-game', 'discrimination-game', 'vision-model-pretraining', 'ablation-study'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze5NQ6rrufq8"
      },
      "source": [
        "## 📖 C. Importing useful libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI_xxovQ8nGD"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime as dt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms as T\n",
        "import torchvision as tv\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss, Precision, Recall, ClassificationReport\n",
        "from ignite.handlers import LRScheduler, ModelCheckpoint, global_step_from_engine\n",
        "from ignite.contrib.handlers import ProgressBar, TensorboardLogger\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "import ignite.contrib.engines.common as common\n",
        "from ignite.contrib.handlers.wandb_logger import *\n",
        "\n",
        "import opendatasets as od\n",
        "import os\n",
        "from random import randint\n",
        "import urllib\n",
        "import zipfile\n",
        "import wandb\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from PIL import ImageFilter\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJXRyyZqbPzT"
      },
      "source": [
        "#### Random **seed initialization** (for *reproducibility*) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNNr6N5EbSN3"
      },
      "outputs": [],
      "source": [
        "hashed_sentence = 'emergent languages are very cool, yes indeed !'\n",
        "get_seed = lambda s: hash(s) % (2**32 - 1)\n",
        "SEED = get_seed(hashed_sentence)\n",
        "\n",
        "# Setting the random seeds of Numpy, PyTorch and Random\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "\n",
        "# Initialize the following parameters in the dataloader :\n",
        "worker_init_fn = seed_worker\n",
        "generator = g\n",
        "\n",
        "# Avoid the following insofar as possible for efficiency purposes :\n",
        "torch.use_deterministic_algorithms(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yIJmtS7vAnr"
      },
      "source": [
        "#### Connecting to WandB :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5lMDjfaooAQ",
        "outputId": "ec4b87f9-24e8-43b6-cf4a-31c5eafc5514"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publically.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to Wandb online interface : True\n"
          ]
        }
      ],
      "source": [
        "def wandb_connect():\n",
        "    wandb_conx = wandb.login(key = WANDB_API_KEY)\n",
        "    print(f\"Connected to Wandb online interface : {wandb_conx}\")\n",
        "\n",
        "wandb_connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrabFad1zohY"
      },
      "source": [
        "## D. Legacy code (*for debugging purposes only, please ignore otherwise*):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWei6nLB88Go"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "preprocess_transform_pretrain = T.Compose([\n",
        "                T.Resize(256), # Resize images to 256 x 256\n",
        "                T.CenterCrop(224), # Center crop image\n",
        "                T.RandomHorizontalFlip(),\n",
        "                T.ToTensor(),  # Converting cropped images to tensors\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                            std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=200)\n",
        "\n",
        "# Move model to designated device (Use GPU when on Colab)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define hyperparameters and settings\n",
        "lr = 0.001  # Learning rate\n",
        "num_epochs = 3  # Number of epochs\n",
        "log_interval = 300  # Number of iterations before logging\n",
        "\n",
        "# Set loss function (categorical Cross Entropy Loss)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set optimizer (using Adam as default)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Setup pytorch-ignite trainer engine\n",
        "trainer = create_supervised_trainer(model, optimizer, loss_func, device=device)\n",
        "\n",
        "# Add progress bar to monitor model training\n",
        "ProgressBar(persist=True).attach(trainer, output_transform=lambda x: {\"Batch Loss\": x})\n",
        "\n",
        "# Define evaluation metrics\n",
        "\n",
        "precision = Precision(average=False)\n",
        "recall = Recall(average=False)\n",
        "\n",
        "metrics = {\n",
        "    \"accuracy\": Accuracy(), \n",
        "    \"loss\": Loss(loss_func),\n",
        "    \"precision\": precision,\n",
        "    \"recall\": recall,\n",
        "    'F1': (precision * recall * 2 / (precision + recall)).mean(),\n",
        "}\n",
        "\n",
        "classification_report = ClassificationReport()\n",
        "classification_report.attach(trainer, \"classification_report\")\n",
        "# res = engine.state.metrics[\"classification_report\"]\n",
        "\n",
        "# Evaluator for training data\n",
        "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
        "\n",
        "# Evaluator for validation data\n",
        "evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
        "\n",
        "# Display message to indicate start of training\n",
        "@trainer.on(Events.STARTED)\n",
        "def start_message():\n",
        "    print(\"Begin training\")\n",
        "\n",
        "# Log results from every batch\n",
        "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
        "def log_batch(trainer):\n",
        "    batch = (trainer.state.iteration - 1) % trainer.state.epoch_length + 1\n",
        "    print(f\"Epoch {trainer.state.epoch} / {num_epochs}, \"\n",
        "          f\"Batch {batch} / {trainer.state.epoch_length}: \"\n",
        "          f\"Loss: {trainer.state.output:.3f}\")\n",
        "\n",
        "# Evaluate and print training set metrics\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_training_loss(trainer):\n",
        "    print(f\"Epoch [{trainer.state.epoch}] - Loss: {trainer.state.output:.2f}\")\n",
        "    train_evaluator.run(train_loader_pretrain)\n",
        "    epoch = trainer.state.epoch\n",
        "    metrics = train_evaluator.state.metrics\n",
        "    print(f\"Train - Loss: {metrics['loss']:.3f}, \"\n",
        "          f\"Accuracy: {metrics['accuracy']:.3f} \")\n",
        "\n",
        "# Evaluate and print validation set metrics\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_loss(trainer):\n",
        "    evaluator.run(val_loader_pretrain)\n",
        "    epoch = trainer.state.epoch\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(f\"Validation - Loss: {metrics['loss']:.3f}, \"\n",
        "          f\"Accuracy: {metrics['accuracy']:.3f}\")\n",
        "\n",
        "# Sets up checkpoint handler to save best n model(s) based on validation accuracy metric\n",
        "common.save_best_model_by_val_score(\n",
        "          output_path=\"best_models\",\n",
        "          evaluator=evaluator, model=model,\n",
        "          metric_name=\"accuracy\", n_saved=1,\n",
        "          trainer=trainer, tag=\"val\")\n",
        "\n",
        "train_loader, val_loader, test_loader = split.values()\n",
        "\n",
        "def run(train_batch_size, val_batch_size, epochs, lr, log_interval):\n",
        "    desc = \"ITERATION - loss: {:.2f}\"\n",
        "    pbar = tqdm(\n",
        "        initial=0, leave=False, total=len(train_loader),\n",
        "        desc=desc.format(0)\n",
        "    )\n",
        "    #WandBlogger Object Creation\n",
        "    wandb_logger = WandBLogger(\n",
        "        project=WANDB_PROJECT,\n",
        "        name=\"cnn-mnist\",\n",
        "        config={\"max_epochs\": epochs, \"batch_size\":train_batch_size},\n",
        "        tags=[\"pytorch-ignite\", \"minst\"]\n",
        "    )\n",
        "\n",
        "    wandb_logger.attach_output_handler(\n",
        "        trainer,\n",
        "        event_name=Events.ITERATION_COMPLETED,\n",
        "        tag=\"training\",\n",
        "        output_transform=lambda loss: {\"loss\": loss}\n",
        "    )\n",
        "\n",
        "    wandb_logger.attach_output_handler(\n",
        "        evaluator,\n",
        "        event_name=Events.EPOCH_COMPLETED,\n",
        "        tag=\"training\",\n",
        "        metric_names=[\"nll\", \"accuracy\"],\n",
        "        global_step_transform=lambda *_: trainer.state.iteration,\n",
        "    )\n",
        "\n",
        "    wandb_logger.attach_opt_params_handler(\n",
        "        trainer,\n",
        "        event_name=Events.ITERATION_STARTED,\n",
        "        optimizer=optimizer,\n",
        "        param_name='lr'  # optional\n",
        "    )\n",
        "\n",
        "    wandb_logger.watch(model)\n",
        "\n",
        "    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
        "    def log_training_loss(engine):\n",
        "        pbar.desc = desc.format(engine.state.output)\n",
        "        pbar.update(log_interval)\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_training_results(engine):\n",
        "        pbar.refresh()\n",
        "        evaluator.run(train_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        avg_accuracy = metrics['accuracy']\n",
        "        avg_nll = metrics['nll']\n",
        "        tqdm.write(\n",
        "            \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "            .format(engine.state.epoch, avg_accuracy, avg_nll)\n",
        "        )\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_results(engine):\n",
        "        evaluator.run(val_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        avg_accuracy = metrics['accuracy']\n",
        "        avg_nll = metrics['nll']\n",
        "        tqdm.write(\n",
        "            \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "            .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
        "\n",
        "        pbar.n = pbar.last_print_n = 0\n",
        "\n",
        "    trainer.run(train_loader, max_epochs=num_epochs)\n",
        "    \n",
        "    pbar.close()\n",
        "\n",
        "next(model.parameters()).is_cuda\n",
        "\n",
        "# Start training\n",
        "run(8, 8, num_epochs, lr, log_interval)\n",
        "\n",
        "print(evaluator.state.metrics)\n",
        "\n",
        "# 1. How to get the number of classes :\n",
        "len(image_datasets['train'].classes)\n",
        "\n",
        "# 2. How to get the typical sizes of the images :\n",
        "for b in train_loader:\n",
        "    print(b[0].size())\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejIp2tKW2J_O"
      },
      "source": [
        "## 👟 E. Parallel runs (training various models on various datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV2KEVbm2_6G"
      },
      "source": [
        "#### Utility functions for **datasets handling** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zffYwbe3bSQ"
      },
      "outputs": [],
      "source": [
        "def generate_dataloaders_from_local(path, num_workers=2, pin_memory=True, val_test_ratio=(0.75, 0.25)):\n",
        "    kwargs = {'num_workers': num_workers, # In order to parallelize dataset loading : interesting :) \n",
        "            'pin_memory': pin_memory} if torch.cuda.is_available() else {}\n",
        "\n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    train_dataset = datasets.ImageFolder(root=path + 'train/', transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                            batch_size=batch_size, \n",
        "                                            shuffle=True, \n",
        "                                            worker_init_fn=worker_init_fn,\n",
        "                                            generator=generator,\n",
        "                                            **kwargs)\n",
        "\n",
        "    __test_dataset__ = datasets.ImageFolder(path + 'val/', transform=transform_val_test)\n",
        "\n",
        "    len_val = int(val_test_ratio[0] * len(__test_dataset__))\n",
        "    len_test = len(__test_dataset__) - len_val\n",
        "    print(\"Number of validation samples : {}\".format(len_val))\n",
        "    print(\"Number of test samples : {}\".format(len_test))\n",
        "\n",
        "    val_dataset, test_dataset = torch.utils.data.random_split(__test_dataset__, [len_val, len_test])\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             batch_size=batch_size, \n",
        "                                             shuffle=True, \n",
        "                                             worker_init_fn=worker_init_fn,\n",
        "                                             generator=generator,\n",
        "                                             **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size, \n",
        "                                              shuffle=True, \n",
        "                                              worker_init_fn=worker_init_fn,\n",
        "                                              generator=generator,\n",
        "                                              **kwargs)\n",
        "\n",
        "    print(\"\\nLength of training dataloader : {}\".format(len(train_loader)))\n",
        "    print(\"Length of validation dataloader : {}\".format(len(val_loader)))\n",
        "    print(\"Length of test dataloader : {}\".format(len(test_loader)))\n",
        "\n",
        "    split_dataloaders = {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader,\n",
        "        'test': test_loader,\n",
        "    }\n",
        "\n",
        "    return split_dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBBeQ48N3AJc"
      },
      "outputs": [],
      "source": [
        "def generate_dataloaders_from_remote(dataset, name='mnist', num_workers=1, pin_memory=True, val_test_ratio=(0.75, 0.25)):\n",
        "    kwargs = {'num_workers': num_workers, # In order to parallelize dataset loading : interesting :) \n",
        "            'pin_memory': pin_memory} if torch.cuda.is_available() else {}\n",
        "\n",
        "    batch_size = params['batch_size']\n",
        "\n",
        "    if name == 'places-365':\n",
        "        train_dataset = dataset(DATASETS_DIR + name\n",
        "                                + '/', split='train-standard', download=True, transform=transform_train)\n",
        "    elif name == 'svhn':\n",
        "        train_dataset = dataset(DATASETS_DIR + name + '/', split='train', download=True, transform=transform_train)\n",
        "    elif name == 'inaturalist':\n",
        "        train_dataset = dataset(DATASETS_DIR + name + '/', version='2021_train', download=True, transform=transform_train)\n",
        "    elif name == 'fake-data':\n",
        "        train_dataset = dataset(size=1_000, image_size=(3, 26, 26), num_classes=10, transform=transform_train)\n",
        "    elif name == 'caltech-101':\n",
        "        full_dataset = dataset(DATASETS_DIR + name + '/', target_type='category', download=True, transform=transform_train)\n",
        "    elif name == 'caltech-256':\n",
        "        full_dataset = dataset(DATASETS_DIR + name + '/', download=True, transform=transform_train)\n",
        "    else:\n",
        "        train_dataset = dataset(DATASETS_DIR + name + '/', train=True, download=True, transform=transform_train)\n",
        "\n",
        "    if name in ['caltech-101', 'caltech-256']:\n",
        "        len_train = int(0.85 * len(full_dataset))\n",
        "        len_val_test = len(full_dataset) - len_train\n",
        "        print(\"Caltech dataset : len_train={}, len_val_test={}\".format(len_train, len_val_test))\n",
        "        train_dataset, __test_dataset__ = torch.utils.data.random_split(full_dataset, lengths=[len_train, len_val_test])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                            batch_size=batch_size, \n",
        "                                            shuffle=True, \n",
        "                                            worker_init_fn=worker_init_fn,\n",
        "                                            generator=generator,\n",
        "                                            **kwargs)\n",
        "    \n",
        "    len_train = len(train_dataset)\n",
        "    print(\"Loading dataset : [{}]\".format(name))\n",
        "    print(\"\\nNumber of training samples : {}\".format(len_train))\n",
        "\n",
        "    if name =='places-365':\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', split='val', download=True, transform=transform_val_test)\n",
        "    elif name =='svhn':\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', split='test', download=True, transform=transform_val_test)\n",
        "    elif name == 'inaturalist':\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', version='2021_valid', download=True, transform=transform_val_test)\n",
        "    elif name == 'fake-data':\n",
        "        __test_dataset__ = dataset(size=100, image_size=(3, 26, 26), num_classes=10, transform=transform_val_test)\n",
        "    elif name in ['caltech-101', 'caltech-256']:\n",
        "        pass\n",
        "    else:\n",
        "        __test_dataset__ = dataset(DATASETS_DIR + name + '/', train=False, download=True, transform=transform_val_test)\n",
        "\n",
        "    len_val = int(val_test_ratio[0] * len(__test_dataset__))\n",
        "    len_test = len(__test_dataset__) - len_val\n",
        "    print(\"Number of validation samples : {}\".format(len_val))\n",
        "    print(\"Number of test samples : {}\".format(len_test))\n",
        "\n",
        "    val_dataset, test_dataset = torch.utils.data.random_split(__test_dataset__, [len_val, len_test])\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             batch_size=batch_size, \n",
        "                                             shuffle=True, \n",
        "                                             worker_init_fn=worker_init_fn,\n",
        "                                             generator=generator,\n",
        "                                             **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size, \n",
        "                                              shuffle=True, \n",
        "                                              worker_init_fn=worker_init_fn,\n",
        "                                              generator=generator,\n",
        "                                              **kwargs)\n",
        "\n",
        "    print(\"\\nBatch size : {}\".format(batch_size))\n",
        "    print(\"\\nLength of training dataloader (in batches) : {}\".format(len(train_loader)))\n",
        "    print(\"Length of validation dataloader (in batches) : {}\".format(len(val_loader)))\n",
        "    print(\"Length of test dataloader (in batches) : {}\".format(len(test_loader)))\n",
        "\n",
        "    split_dataloaders = {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader,\n",
        "        'test': test_loader,\n",
        "    }\n",
        "\n",
        "    return split_dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEUT632qIMhw"
      },
      "source": [
        "#### Data **augmentation** (image **transforms**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcvENqawIHZH"
      },
      "outputs": [],
      "source": [
        "class GaussianBlur():\n",
        "    def __init__(self, sigma=[0.1, 2.0]):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
        "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
        "        return x\n",
        "\n",
        "class TransformsAugment():\n",
        "    def __init__(self, size, multi_channel=True):\n",
        "        print(\"Transforms Augment\")\n",
        "        s = 1\n",
        "        color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "        transformations = [\n",
        "            T.RandomResizedCrop(size=size),\n",
        "            T.RandomApply([color_jitter], p=0.8),\n",
        "            T.RandomGrayscale(p=0.2),\n",
        "            T.RandomApply([GaussianBlur([0.1, 2.0])], p=0.5),\n",
        "            T.RandomHorizontalFlip(),  # with 0.5 probability\n",
        "            T.ToTensor(),\n",
        "        ]\n",
        "        # We \"pseudo-colorize\" the image by broadcasting to the three dimensions\n",
        "        if not multi_channel:\n",
        "            # Solution : number 1 : we simply broadcast the pixel information over all three channels,\n",
        "            # but the main problem is that this is suboptimal\n",
        "            # transformations.append(T.Lambda(lambda x: x[0:1, :, :]))\n",
        "            transformations.append(T.Lambda(lambda x: x.repeat(3,1,1)))\n",
        "\n",
        "            print(\"Not multi-channel\")\n",
        "\n",
        "        transformations.append(\n",
        "            T.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        )\n",
        "        self.transform = T.Compose(transformations)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x_trans = self.transform(x)\n",
        "        return x_trans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDBvi8-327hG"
      },
      "source": [
        "#### Utility functions for **models handling** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1olRBLj26jY",
        "outputId": "05638d8b-6c6c-419b-b6b3-7e49df7602fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrained vision models successfully downloaded\n"
          ]
        }
      ],
      "source": [
        "def get_vision_module(version: str):\n",
        "    \"\"\"\n",
        "    Loads ResNet & EfficientNet encoders from torchvision along with the final features number\n",
        "    \"\"\"\n",
        "\n",
        "    os.environ['TORCH_HOME'] = PRETRAINED_MODELS_DIR # Used in order to specify where to save the pretrained models, so as not to load them again in the future\n",
        "\n",
        "    resnets = {\n",
        "        \"resnet-18\": (lambda: tv.models.resnet18(pretrained=True, progress=True)),\n",
        "        \"resnet-34\": (lambda: tv.models.resnet34(pretrained=True, progress=True)),\n",
        "        \"resnet-50\": (lambda: tv.models.resnet50(pretrained=True, progress=True)),\n",
        "        \"resnet-101\": (lambda: tv.models.resnet101(pretrained=True, progress=True)),\n",
        "        \"resnet-152\": (lambda: tv.models.resnet152(pretrained=True, progress=True)),\n",
        "    }\n",
        "\n",
        "    efficientnets = {\n",
        "        \"efficientnet-b0\": (lambda: tv.models.efficientnet_b0(pretrained=True, progress=True)),\n",
        "        \"efficientnet-b1\": (lambda: tv.models.efficientnet_b1(pretrained=True, progress=True)),\n",
        "        \"efficientnet-b2\": (lambda: tv.models.efficientnet_b2(pretrained=True, progress=True)),\n",
        "        \"efficientnet-b3\": (lambda: tv.models.efficientnet_b3(pretrained=True, progress=True)),\n",
        "        \"efficientnet-b4\": (lambda: tv.models.efficientnet_b4(pretrained=True, progress=True)),\n",
        "        \"efficientnet-b5\": (lambda: tv.models.efficientnet_b5(pretrained=True, progress=True)),\n",
        "        \"efficientnet-b6\": (lambda: tv.models.efficientnet_b6(pretrained=True, progress=True)),\n",
        "        \"efficientnet-b7\": (lambda: tv.models.efficientnet_b7(pretrained=True, progress=True)),\n",
        "    }\n",
        "\n",
        "    if (version not in resnets) and (version not in efficientnets):\n",
        "        raise KeyError(f\"{version} is not a valid ResNet / EfficientNet version\")\n",
        "\n",
        "    models_library = {**resnets, **efficientnets}\n",
        "\n",
        "    model = models_library[version]()\n",
        "    \n",
        "    # features_dim = model.fc.in_features\n",
        "    # model.fc = nn.Identity()\n",
        "\n",
        "    return model #, features_dim\n",
        "\n",
        "try:\n",
        "    get_vision_module('downloading')\n",
        "except:\n",
        "    print(\"Pretrained vision models successfully downloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKevK1573Ab-"
      },
      "source": [
        "#### Utility functions for **memory management** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CDrsVq63Ap_"
      },
      "outputs": [],
      "source": [
        "def free_memory(model, *args):\n",
        "    # Now, we free the available memory in order to launch other training experiments.\n",
        "    print(\"Freeing memory ...\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    for x in args:\n",
        "        x = None\n",
        "        del x\n",
        "    print(\"Successfully freed some memory !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTVDny205E9c"
      },
      "source": [
        "### Utility function in order to properly adapt a three-channel dataset in order to take as inputs images from a one-channel dataset, such as MNIST :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tmiXkAIN5Nom",
        "outputId": "cc6c3673-8bc8-4ae0-9fdc-bb70a5880a70"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef adapt_to_3_channels(model_constructor):\\n    class ModelTo3Channel(ResNet):\\n        def __init__(self):\\n            super(ModelTo3Channel, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\\n            self.conv1 = torch.nn.Conv2d(1, 64, \\n                kernel_size=(7, 7), \\n                stride=(2, 2), \\n                padding=(3, 3), bias=False)\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "def adapt_to_3_channels(model_constructor):\n",
        "    class ModelTo3Channel(ResNet):\n",
        "        def __init__(self):\n",
        "            super(ModelTo3Channel, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "            self.conv1 = torch.nn.Conv2d(1, 64, \n",
        "                kernel_size=(7, 7), \n",
        "                stride=(2, 2), \n",
        "                padding=(3, 3), bias=False)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0WfqlpT2Yzb"
      },
      "source": [
        "#### Instantiating dataloaders into **'train' / 'val' / 'test' splits** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAYuzQEQ2O15"
      },
      "outputs": [],
      "source": [
        "split_dataloaders = {\n",
        "    'train': None,\n",
        "    'val': None,\n",
        "    'test': None,\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'cifar-10': split_dataloaders,\n",
        "    'cifar-100': split_dataloaders,\n",
        "    'mnist': split_dataloaders,\n",
        "    'tiny-imagenet': split_dataloaders,\n",
        "    'fashion-mnist': split_dataloaders,\n",
        "    'q-mnist': split_dataloaders,\n",
        "    'k-mnist': split_dataloaders,\n",
        "    'svhn': split_dataloaders,\n",
        "    'caltech-101': split_dataloaders,\n",
        "    'caltech-256': split_dataloaders,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6SaC-ZPykrb"
      },
      "outputs": [],
      "source": [
        "image_datasets.update({\n",
        "    'imagenet': split_dataloaders,\n",
        "    'places-365': split_dataloaders,\n",
        "    'inaturalist': split_dataloaders,\n",
        "    'fake-data': split_dataloaders,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jILDM3Sb22IE"
      },
      "source": [
        "#### **Loading** them either **from memory** (if already downloaded or manually downloaded) or **from the datasets hub**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyE_4lDl2eTx"
      },
      "outputs": [],
      "source": [
        "image_datasets['cifar-10'] = lambda: generate_dataloaders_from_remote(datasets.CIFAR10, name='cifar-10')\n",
        "image_datasets['cifar-100'] = lambda: generate_dataloaders_from_remote(datasets.CIFAR100, name='cifar-100')\n",
        "image_datasets['mnist'] = lambda: generate_dataloaders_from_remote(datasets.MNIST, name='mnist')\n",
        "image_datasets['tiny-imagenet'] = lambda: generate_dataloaders_from_local(DATASETS_DIR + DATASET_TINY_IMAGENET_DIR)\n",
        "image_datasets['fashion-mnist'] = lambda: generate_dataloaders_from_remote(datasets.FashionMNIST, name='fashion-mnist')\n",
        "image_datasets['q-mnist'] = lambda: generate_dataloaders_from_remote(datasets.QMNIST, name='q-mnist')\n",
        "image_datasets['k-mnist'] = lambda: generate_dataloaders_from_remote(datasets.KMNIST, name='k-mnist')\n",
        "image_datasets['svhn'] = lambda: generate_dataloaders_from_remote(datasets.SVHN, name='svhn')\n",
        "image_datasets['caltech-101'] = lambda: generate_dataloaders_from_remote(datasets.Caltech101, name='caltech-101')\n",
        "image_datasets['caltech-256'] = lambda: generate_dataloaders_from_remote(datasets.Caltech256, name='caltech-256')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpLnnJbZybT9"
      },
      "outputs": [],
      "source": [
        "image_datasets['inaturalist'] = lambda: generate_dataloaders_from_remote(datasets.INaturalist, name='inaturalist')\n",
        "image_datasets['places-365'] = lambda: generate_dataloaders_from_remote(datasets.Places365, name='places-365')\n",
        "image_datasets['imagenet'] = lambda: generate_dataloaders_from_local(DATASETS_DIR + DATASET_IMAGENET_DIR)\n",
        "image_datasets['fake-data'] = lambda: generate_dataloaders_from_remote(datasets.FakeData, name='fake-data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNAFoZ0-LaWh"
      },
      "source": [
        "#### Standard image sizes for each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhEzq96HLdVa"
      },
      "outputs": [],
      "source": [
        "sizes = {\n",
        "    'cifar-10': 32,\n",
        "    'cifar-100': 32,\n",
        "    'mnist': 28,\n",
        "    'imagenet': 256,\n",
        "    'tiny-imagenet': 64,\n",
        "    'fashion-mnist': 28,\n",
        "    'places-365': 256,\n",
        "    'inaturalist': 256, # the dimension to resize the images to, but they may be actually higher-def (up to 2,048 px)\n",
        "    'fake-data': 224,\n",
        "    'q-mnist': 28,\n",
        "    'k-mnist': 28,\n",
        "    'svhn': 32,\n",
        "    'caltech-101': 64, # there are actually sizes for each image - therefore we round up to the average value\n",
        "    'caltech-256': 64, # same\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1z68qDW7QSl"
      },
      "source": [
        "### 1. Training all models on **CIFAR-100** and **MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaP6czzhNjUx"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'batch_size': 64,\n",
        "    'num_epochs': 5,\n",
        "    'log_interval': 100,\n",
        "    'lr': 0.001,\n",
        "}\n",
        "\n",
        "TEST_ONE_BATCH = False\n",
        "LOG_TO_WANDB = True\n",
        "\n",
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass\n",
        "\n",
        "# raise StopExecution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxxCLyV1HDuL"
      },
      "outputs": [],
      "source": [
        "def finetune(model='resnet-50', dataset='cifar-10', num_epochs=None, add_name=None):\n",
        "    global transform_train, transform_val_test, params\n",
        "\n",
        "    if add_name is None:\n",
        "        NAME_RUN = f'Vision model pretraining : M[{model}], D[{dataset}]'\n",
        "        NAME_CHECKPOINT = f'model={model}_dataset={dataset}'\n",
        "    else:\n",
        "        NAME_RUN = f'Vision model pretraining : M[{model}], D[{dataset}], D[{add_name}]'\n",
        "        NAME_CHECKPOINT = f'model={model}_dataset={dataset}_cond={add_name}'\n",
        "        \n",
        "    DIR_CHECKPOINT = FINETUNED_MODELS_DIR + NAME_CHECKPOINT + '/'\n",
        "\n",
        "    model_name = model\n",
        "\n",
        "    params = copy.deepcopy(params)\n",
        "    if num_epochs is not None:\n",
        "        params['num_epochs'] = num_epochs\n",
        "\n",
        "    print(\"Training parameters :\", params)\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # 1. Instantiating the model and the optimization routine\n",
        "    # -------------------------------------------------------\n",
        "    # Move model to designated device (Use GPU when on Colab)\n",
        "    model = get_vision_module(version=model)\n",
        "    # model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=200)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define hyperparameters and settings\n",
        "\n",
        "    # Set loss function (categorical Cross Entropy Loss)\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Set optimizer (using Adam as default)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
        "\n",
        "    # ----------------------------------------\n",
        "    # 2. Defining the data augmentation scheme\n",
        "    # ----------------------------------------\n",
        "    multi_channel = not dataset in ['mnist', 'k-mnist', 'q-mnist', 'fashion-mnist']\n",
        "    transform_train = TransformsAugment(size=sizes[dataset], multi_channel=multi_channel)\n",
        "    transform_val_test = TransformsAugment(size=sizes[dataset], multi_channel=multi_channel)\n",
        "\n",
        "    # -----------------------\n",
        "    # 3. Creating the trainer\n",
        "    # -----------------------\n",
        "    # Setup pytorch-ignite trainer engine\n",
        "    trainer = create_supervised_trainer(model, optimizer, loss_func, device=device)\n",
        "\n",
        "    # Add progress bar to monitor model training\n",
        "    ProgressBar(persist=True).attach(trainer, output_transform=lambda x: {\"Batch Loss\": x})\n",
        "\n",
        "    # ------------------------------\n",
        "    # 4. Defining evaluation metrics\n",
        "    # ------------------------------\n",
        "\n",
        "    __precision__ = Precision(average=False)\n",
        "    __recall__ = Recall(average=False)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": Accuracy(), \n",
        "        \"loss\": Loss(loss_func),\n",
        "        \"precision\": Precision(average=True),\n",
        "        \"recall\": Recall(average=True),\n",
        "        'F1': (__precision__ * __recall__ * 2 / (__precision__ + __recall__)).mean(),\n",
        "    }\n",
        "\n",
        "    # classification_report = ClassificationReport()\n",
        "    # classification_report.attach(trainer, \"classification_report\")\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    # 5. Defining the supervised classification task\n",
        "    # ----------------------------------------------\n",
        "    # Evaluator for training data\n",
        "    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
        "\n",
        "    # Evaluator for validation data\n",
        "    evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
        "\n",
        "    # -------------------------------\n",
        "    # 6. Instantiating the dataloader\n",
        "    # -------------------------------\n",
        "    split = image_datasets[dataset]()\n",
        "    train_loader, val_loader, test_loader = split.values()\n",
        "\n",
        "    # -------------------------------------------\n",
        "    # 7. Utility functions for experiment logging\n",
        "    # -------------------------------------------\n",
        "    @trainer.on(Events.STARTED)\n",
        "    def start_message():\n",
        "        print(\"Begin training\")\n",
        "\n",
        "    # Log results from every batch\n",
        "    @trainer.on(Events.ITERATION_COMPLETED(every=params['log_interval']))\n",
        "    def log_batch(trainer):\n",
        "        batch = (trainer.state.iteration - 1) % trainer.state.epoch_length + 1\n",
        "        print(f\"Epoch {trainer.state.epoch} / {params['num_epochs']}, \"\n",
        "            f\"Batch {batch} / {trainer.state.epoch_length}: \"\n",
        "            f\"Loss: {trainer.state.output:.3f}\")\n",
        "        \"\"\"\n",
        "        evaluator.run(val_loader)\n",
        "        epoch = trainer.state.epoch\n",
        "        metrics = evaluator.state.metrics\n",
        "        print(metrics)\n",
        "        print(f\"Val - Loss: {metrics['loss']:.3f}, \",\n",
        "              f\"Val - Accuracy: {metrics['accuracy']:.3f}, \",\n",
        "              f\"Val - Precision: {metrics['precision']:.3f}, \",\n",
        "              f\"Val - Recall: {metrics['recall']:.3f}, \",\n",
        "              f\"Val - F1: {metrics['F1']:.3f}, \",)\n",
        "        \"\"\"\n",
        "\n",
        "    # Evaluate and print training set metrics\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_training_loss(trainer):\n",
        "        print(f\"Epoch [{trainer.state.epoch}] - Loss: {trainer.state.output:.2f}\")\n",
        "        train_evaluator.run(train_loader)\n",
        "        epoch = trainer.state.epoch\n",
        "        metrics = train_evaluator.state.metrics\n",
        "        print(metrics)\n",
        "        print(f\"[E] Train - Loss: {metrics['loss']:.3f}, \",\n",
        "              f\"[E] Train - Accuracy: {metrics['accuracy']:.3f}, \",\n",
        "              f\"[E] Train - Precision: {metrics['precision']:.3f}, \",\n",
        "              f\"[E] Train - Recall: {metrics['recall']:.3f}, \",\n",
        "              f\"[E] Train - F1: {metrics['F1']:.3f}, \",)\n",
        "\n",
        "    # Evaluate and print validation set metrics\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_loss(trainer):\n",
        "        evaluator.run(val_loader)\n",
        "        epoch = trainer.state.epoch\n",
        "        metrics = evaluator.state.metrics\n",
        "        print(f\"[E] Val - Loss: {metrics['loss']:.3f}, \",\n",
        "              f\"[E] Val - Accuracy: {metrics['accuracy']:.3f}, \",\n",
        "              f\"[E] Val - Precision: {metrics['precision']:.3f}, \",\n",
        "              f\"[E] Val - Recall: {metrics['recall']:.3f}, \",\n",
        "              f\"[E] Val - F1: {metrics['F1']:.3f}, \",)\n",
        "\n",
        "    # Sets up checkpoint handler to save best n model(s) based on validation accuracy metric\n",
        "    common.save_best_model_by_val_score(\n",
        "            output_path=DIR_CHECKPOINT,\n",
        "            evaluator=evaluator, model=model,\n",
        "            metric_name=\"accuracy\", n_saved=5,\n",
        "            trainer=trainer, tag=\"val\")\n",
        "\n",
        "    # Sets up Early Stopping\n",
        "    common.add_early_stopping_by_val_score(\n",
        "            patience=100, \n",
        "            evaluator=evaluator, \n",
        "            trainer=trainer, \n",
        "            metric_name='accuracy',\n",
        "            )\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # 8. Other helper functions - WandB Logging\n",
        "    # -----------------------------------------\n",
        "    desc = \"ITERATION - loss: {:.2f}\"\n",
        "    pbar = tqdm(\n",
        "        initial=0, leave=False, total=len(train_loader),\n",
        "        desc=desc.format(0)\n",
        "    )\n",
        "\n",
        "    if LOG_TO_WANDB:\n",
        "        #WandBlogger Object Creation\n",
        "        wandb_logger = WandBLogger(\n",
        "            project=WANDB_PROJECT,\n",
        "            name=NAME_RUN,\n",
        "            config={\"max_epochs\": params['num_epochs'], \"batch_size\": params['batch_size']},\n",
        "            tags=[model_name, dataset],\n",
        "            group=WANDB_EXPERIMENT_GROUP,\n",
        "        )\n",
        "\n",
        "        wandb_logger.attach_output_handler(\n",
        "            trainer,\n",
        "            event_name=Events.ITERATION_COMPLETED,\n",
        "            tag=\"training\",\n",
        "            output_transform=lambda loss: {\"loss\": loss}\n",
        "        )\n",
        "\n",
        "        wandb_logger.attach_output_handler(\n",
        "            evaluator,\n",
        "            event_name=Events.EPOCH_COMPLETED,\n",
        "            tag=\"training\",\n",
        "            metric_names=[\"nll\", \"accuracy\", \"precision\", \"recall\", \"F1\"],\n",
        "            global_step_transform=lambda *_: trainer.state.iteration,\n",
        "        )\n",
        "\n",
        "        wandb_logger.attach_opt_params_handler(\n",
        "            trainer,\n",
        "            event_name=Events.ITERATION_STARTED,\n",
        "            optimizer=optimizer,\n",
        "            param_name='lr'  # optional\n",
        "        )\n",
        "\n",
        "        wandb_logger.watch(model)\n",
        "\n",
        "    @trainer.on(Events.ITERATION_COMPLETED(every=params['log_interval']))\n",
        "    def log_training_loss(engine):\n",
        "        pbar.desc = desc.format(engine.state.output)\n",
        "        pbar.update(params['log_interval'])\n",
        "        \n",
        "        if TEST_ONE_BATCH:\n",
        "            raise StopExecution\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_training_results(engine):\n",
        "        pbar.refresh()\n",
        "        evaluator.run(train_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        avg_accuracy = metrics['accuracy']\n",
        "        avg_loss = metrics['loss']\n",
        "        avg_precision = metrics['precision']\n",
        "        avg_recall = metrics['recall']\n",
        "        avg_f1 = metrics['F1']\n",
        "        tqdm.write(\n",
        "            \"Training Results - Epoch: {}  Avg accuracy: {:.2f}  Avg loss: {:.2f}  Avg precision: {:.2f}  Avg recall: {:.2f}  Avg F1: {:.2f}\"\n",
        "            .format(engine.state.epoch, avg_accuracy, avg_loss, avg_precision, avg_recall, avg_f1)\n",
        "        )\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_validation_results(engine):\n",
        "        evaluator.run(val_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        avg_accuracy = metrics['accuracy']\n",
        "        avg_loss = metrics['loss']\n",
        "        avg_precision = metrics['precision']\n",
        "        avg_recall = metrics['recall']\n",
        "        avg_f1 = metrics['F1']\n",
        "        tqdm.write(\n",
        "            \"Validation Results - Epoch: {}  Avg accuracy: {:.2f}  Avg loss: {:.2f}  Avg precision: {:.2f}  Avg recall: {:.2f}  Avg F1: {:.2f}\"\n",
        "            .format(engine.state.epoch, avg_accuracy, avg_loss, avg_precision, avg_recall, avg_f1))\n",
        "\n",
        "        pbar.n = pbar.last_print_n = 0\n",
        "\n",
        "    handler = ModelCheckpoint(DIR_CHECKPOINT, 'last_models', n_saved=1, create_dir=True)\n",
        "    trainer.add_event_handler(Events.EPOCH_COMPLETED(every=1), handler, {'model': model})\n",
        "\n",
        "    trainer.run(train_loader, max_epochs=params['num_epochs'])\n",
        "    \n",
        "    pbar.close()\n",
        "\n",
        "    print(\"Displaying the final metrics : \")\n",
        "    print(evaluator.state.metrics)\n",
        "\n",
        "    evaluator.run(test_loader)\n",
        "    metrics = train_evaluator.state.metrics\n",
        "    print(metrics)\n",
        "    print(f\"Train - Loss: {metrics['loss']:.3f}, \",\n",
        "            f\"Accuracy: {metrics['accuracy']:.3f}, \",\n",
        "            f\"Precision: {metrics['precision']:.3f}, \",\n",
        "            f\"Recall: {metrics['recall']:.3f}, \",\n",
        "            f\"F1: {metrics['F1']:.3f}, \",)\n",
        "\n",
        "    free_memory([model, train_loader, val_loader])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4x6qlEj_tF2"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-18', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgtaFP_z7_FB"
      },
      "source": [
        "#### In order to just forward one batch of samples through each model in order to check that training goes smoothly, please set :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ9INM_t7-aW"
      },
      "outputs": [],
      "source": [
        "#@title Decide whether to test ablation on a single batch or to run the full ablation study { run: \"auto\", vertical-output: true, form-width: \"65%\", display-mode: \"code\" }\n",
        "\n",
        "option = \"Full ablation\" #@param [\"Single batch\", \"Full ablation\"]\n",
        "\n",
        "if option == \"Single batch\":\n",
        "    TEST_ONE_BATCH = True\n",
        "    LOG_TO_WANDB = False\n",
        "    params['log_interval'] = 10\n",
        "else:\n",
        "    TEST_ONE_BATCH = False\n",
        "    LOG_TO_WANDB = True\n",
        "    params['log_interval'] = 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eub5MN2S7ajE"
      },
      "source": [
        "#### 🔸 **Resnet-18**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwZRloi5d55q"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-18', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4MUvVPX7X65"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-18', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7etEEmxBAsu"
      },
      "source": [
        "#### 🔸🔸 **Resnet-34**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZTQrzsIBA84"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-34', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qb851BRBuOJ"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-34', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAf6sQzLBBLv"
      },
      "source": [
        "#### 🔸🔸🔸 **Resnet-50** (default *Resnet* model, which we will train longer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7rJscs5BBXt"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOAN2P2uBuot"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXjQ8eXUBBmz"
      },
      "source": [
        "#### 🔸🔸🔸🔸 **Resnet-101**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF6LVk-IBB4A"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-101', dataset='cifar-100') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqzNiPcMBu6a"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-101', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLYjqIw2BCH4"
      },
      "source": [
        "#### 🔸🔸🔸🔸🔸 **Resnet-152**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LWXYki-BCnp"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-152', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3tvvTIKBvJR"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-152', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_jJOe-UBQ-s"
      },
      "source": [
        "#### 🔹 **EfficientNet-B0** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i4jW-F-BQmv"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b0', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njLFzfNfBvcB"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b0', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cpZp3WgBSkA"
      },
      "source": [
        "#### 🔹🔹 **EfficientNet-B1** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0wzhk0TBSy2"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b1', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHAQYPBOBwJl"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b1', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W855juQlBTL6"
      },
      "source": [
        "#### 🔹🔹🔹 **EfficientNet-B2** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROKMXABOBTYZ"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b2', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgJmFfWpBwaQ"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b2', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eee8xczD7YLh"
      },
      "source": [
        "🔹🔹🔹🔹 #### **EfficientNet-B3** (default *EfficientNet* model, which we will train longer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9diA5YiI7Ybq"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vgf3wp6ABwqr"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4Anl79BPr4"
      },
      "source": [
        "#### 🔹🔹🔹🔹🔹 **EfficientNet-B4** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M2ngzip9BTt9"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b4', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDw3UtgFBw73"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b4', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icj66KzbBUBx"
      },
      "source": [
        "#### 🔹🔹🔹🔹🔹🔹 **EfficientNet-B5** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKV-g17qBUS-"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b5', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jRAmZejPBxTi"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b5', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xPWMRsyBUuW"
      },
      "source": [
        "#### 🔹🔹🔹🔹🔹🔹🔹 **EfficientNet-B6** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PDtQL1g2BVAB"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b6', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XQ9qJygQBxpK"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b6', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhTlOT6VBVZQ"
      },
      "source": [
        "#### 🔹🔹🔹🔹🔹🔹🔹🔹 **EfficientNet-B7** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoUa76MlBVvq"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b7', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-VRsHigByFT"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b7', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzqD8nXU7YvA"
      },
      "source": [
        "### 2. Training **Resnet-50** and *EfficientNet-B3* on all datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1KD39Nc7qGd"
      },
      "source": [
        "#### 🏞 CIFAR-10 🏞 (Privileged dataset n°1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOmfWeIR7ZFl"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='cifar-10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51GiUy0JBy9B"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='cifar-10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--h9vgkGasWH"
      },
      "source": [
        "#### Privileged runs (models trained longer) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnvAM4bxaq6r"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='cifar-10', num_epochs=50, add_name='longer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8-BPnr5aroP"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='cifar-10', num_epochs=50, add_name='longer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nboVkkv7rOT"
      },
      "source": [
        "#### 🏞 CIFAR-100 🏞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofIF_C6P7q8W"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quFMKC-RBzOe"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='cifar-100')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSW2fn_67rku"
      },
      "source": [
        "#### 🔢 MNIST 🔢 (Privileged dataset n°1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1aZ9G7d7rzm"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='mnist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0MibeViBzjD"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUExyJgOaxV3"
      },
      "source": [
        "#### Privileged runs (models trained longer) :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HX6CbHQa2Tp"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='mnist', num_epochs=50, add_name='longer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg280dC9a26Y"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='mnist', num_epochs=50, add_name='longer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE5hUduV7r_X"
      },
      "source": [
        "#### 🪐 ImageNet 🪐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bSNiF9G7sSS"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='imagenet', num_epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTxau4LZBzxG"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='imagenet', num_epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJlEhmfv7uA-"
      },
      "source": [
        "#### 🪐 TinyImageNet 🪐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gu5MRi-7uPj"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='tiny-imagenet', num_epochs=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U_EJxAlB0kJ"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='tiny-imagenet', num_epochs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55et6Vjp7ubC"
      },
      "source": [
        "#### 🥋 FashionMNIST 🥋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utib-X6P7u0y"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='fashion-mnist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXBOJuOrB01m"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='fashion-mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEvAgU47vEb"
      },
      "source": [
        "#### 🌉 Places365 🌉 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlSdX1De7vUk"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='places-365', num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq8BUWx9B1Jo"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='places-365', num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5ndQxjD7vhX"
      },
      "source": [
        "#### 🌿 iNaturalist 🌿"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmgBenSp7v8a"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='inaturalist', num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FFOa837B1du"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='inaturalist', num_epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC3o2Nk37wNW"
      },
      "source": [
        "#### 🤡 FakeData 🤡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEDmnlh67wmn"
      },
      "outputs": [],
      "source": [
        "# finetune(model='resnet-50', dataset='fake-data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC2v1WUQB2YC"
      },
      "outputs": [],
      "source": [
        "# finetune(model='efficientnet-b3', dataset='fake-data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__HVHo0S8I_F"
      },
      "source": [
        "#### 🧾 QMNIST 🧾"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ73LYCD8JPN"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='q-mnist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI6tLGVlB2nZ"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='q-mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncNhAOVO8JbN"
      },
      "source": [
        "#### 🔖 KMNIST 🔖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j__aR-JP8Js8"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='k-mnist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cdi69f4EB27N"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='k-mnist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qPGQ9Fr8NvR"
      },
      "source": [
        "#### 🗻 SVHN 🗻"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpSLr6AA8OCR"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='svhn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etuVq-Y6B3RE"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='svhn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekohGzo68OVA"
      },
      "source": [
        "#### 🪑 Caltech-101 🪑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ANInN1f8Ojl"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='caltech-101')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1BKS9yeB3ow"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='caltech-101')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFnGh5M18soK"
      },
      "source": [
        "#### 💺 Caltech-256 💺"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjyLiTT38s4B"
      },
      "outputs": [],
      "source": [
        "finetune(model='resnet-50', dataset='caltech-256')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw33R-l5B37i"
      },
      "outputs": [],
      "source": [
        "finetune(model='efficientnet-b3', dataset='caltech-256')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Finetuning Vision Models on specific datasets",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
